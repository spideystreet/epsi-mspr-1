# üó≥Ô∏è Pr√©dicteur de R√©sultats √âlectoraux

## ‚ú® Aper√ßu
Ce projet a pour but de pr√©dire les r√©sultats des √©lections fran√ßaises par d√©partement en utilisant des techniques de machine learning. L'objectif n'est pas seulement de pr√©dire, mais de construire un **pipeline robuste, reproductible et m√©thodologiquement correct** qui √©vite les pi√®ges courants de l'analyse de donn√©es temporelles.

##  ÌïµÏã¨ La D√©marche Cl√© du Projet
Le d√©fi principal de ce projet est de pr√©dire un √©v√©nement futur (une √©lection) en se basant sur des donn√©es pass√©es. Pour cela, notre d√©marche repose sur trois piliers :

1.  **Division Temporelle Stricte :** Pour √©viter toute "fuite de donn√©es" du futur vers le pass√©, nous entra√Ænons nos mod√®les exclusivement sur les donn√©es **ant√©rieures √† 2024** et nous les √©valuons sur les donn√©es de **2024**.
2.  **Score d'Exactitude Honn√™te :** Le score de performance de notre mod√®le (~48%) peut sembler modeste, mais il est **r√©aliste**. Il repr√©sente la v√©ritable capacit√© du mod√®le √† pr√©dire une ann√©e qu'il n'a jamais vue, ce qui est bien plus fiable qu'un score artificiellement √©lev√©.
3.  **Simulation pour 2027 :** Nous ne pr√©tendons pas "pr√©dire l'avenir". Nous utilisons nos donn√©es les plus r√©centes (2024) comme une estimation des conditions socio-√©conomiques de 2027, et nous demandons au mod√®le : *"selon les tendances apprises, qui gagnerait si une √©lection avait lieu dans ces conditions ?"*.

## üöÄ Notre Pipeline de Travail
Le projet est structur√© en 3 notebooks s√©quentiels qui forment un pipeline complet et automatis√©, de la donn√©e brute au r√©sultat final.

1.  `notebooks/data_preprocessing.ipynb`
    *   **R√¥le :** Pr√©parer et nettoyer les donn√©es.
    *   **Actions :** Agr√©ger les donn√©es brutes, les charger dans une base de donn√©es PostgreSQL, appliquer la division temporelle (train < 2024, test = 2024), et sauvegarder les jeux de donn√©es trait√©s ainsi que les outils de transformation (`preprocessor`).

2.  `notebooks/model_training.ipynb`
    *   **R√¥le :** Entra√Æner et s√©lectionner le meilleur mod√®le.
    *   **Actions :** Tester plusieurs algorithmes (Random Forest, etc.), les √©valuer sur le jeu de test de 2024, et **sauvegarder automatiquement le mod√®le le plus performant**.

3.  `notebooks/prediction.ipynb`
    *   **R√¥le :** G√©n√©rer les pr√©dictions finales et pr√©parer les donn√©es pour la BI.
    *   **Actions :** Charger le meilleur mod√®le, pr√©dire les gagnants de "2027", et cr√©er une table finale `election_results_for_bi` dans la base de donn√©es, combinant tous les r√©sultats historiques et futurs pour une analyse facile.

## üìÇ Structure des Fichiers
```
.
‚îú‚îÄ‚îÄ data/                 # Jeux de donn√©es bruts (.csv)
‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îú‚îÄ‚îÄ preprocessor_X.joblib # Outil de transformation sauvegard√©
‚îÇ   ‚îî‚îÄ‚îÄ label_encoder_y.joblib  # Encodeur de la cible sauvegard√©
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ random_forest_predictor.joblib # Meilleur mod√®le de pr√©diction
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ model_training.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ prediction.ipynb
‚îú‚îÄ‚îÄ .env.example          # Fichier d'exemple pour les variables d'environnement
‚îú‚îÄ‚îÄ .env                  # Fichier de configuration (ignor√© par git)
‚îú‚îÄ‚îÄ Dockerfile            # D√©finit l'environnement de l'application
‚îú‚îÄ‚îÄ docker-compose.yml    # Orchestre les services Docker
‚îú‚îÄ‚îÄ run_project.sh        # Script d'ex√©cution du pipeline
‚îú‚îÄ‚îÄ README.md               # Ce fichier
‚îî‚îÄ‚îÄ requirements.txt        # D√©pendances du projet
```

## üìä Donn√©es Utilis√©es
Notre jeu de donn√©es comprend :
- R√©sultats √©lectoraux historiques (participation, inscrits, votes par parti).
- Indicateurs socio-√©conomiques (ch√¥mage, pauvret√©).
- Donn√©es sociales (criminalit√©, immigration).

## üê≥ Installation et Lancement avec Docker

### Pr√©requis
- [Docker](https://www.docker.com/get-started)
- [Docker Compose](https://docs.docker.com/compose/install/)

### Lancement
1.  **Clonez le d√©p√¥t** et naviguez dans le dossier.
2.  **Configurez votre environnement :**
    -   Cr√©ez un fichier `.env` en copiant le mod√®le ` .env.example`.
    -   Remplissez les variables d'environnement (`PG_USER`, `PG_PASSWORD`, `PG_DBNAME`, `PG_PORT`) avec vos informations.
3.  **Lancez le projet :**
    -   Ouvrez un terminal √† la racine du projet et ex√©cutez la commande suivante :
      ```bash
      docker-compose up --build
      ```
    -   Cette unique commande va :
        1.  Construire l'image de votre application.
        2.  D√©marrer un conteneur pour la base de donn√©es PostgreSQL.
        3.  D√©marrer le conteneur de l'application qui ex√©cutera automatiquement le script `run_project.sh`.
        4.  Le script attendra que la base de donn√©es soit pr√™te, puis lancera les 3 notebooks en s√©quence, peuplant la base et entra√Ænant le mod√®le.

4.  **Acc√©der aux r√©sultats :**
    -   La base de donn√©es PostgreSQL est accessible depuis votre machine locale sur le port que vous avez d√©fini dans le fichier `.env` (par exemple : `localhost:5432`).
    -   Les notebooks ex√©cut√©s sont sauvegard√©s dans le dossier `notebooks/` avec le suffixe `.executed.ipynb`.

5.  **Pour arr√™ter les services :**
    -   Appuyez sur `Ctrl + C` dans le terminal, puis ex√©cutez :
      ```bash
      docker-compose down
      ```

## üìÑ Licence
Ce projet est sous licence selon les termes du fichier LICENSE.

## üë• L'√âquipe
- [@hicham](https://github.com/spideystreet)
- [@amine](https://github.com/testt753)
- [@wassim](https://github.com/Wassim38)

## üí¨ Feedback
Vous avez des suggestions ou des questions ? N'h√©sitez pas √† ouvrir une issue ou √† nous contacter directement ! 