# üó≥Ô∏è Electoral Results Predictor & Interactive Dashboard

**Master EISI Project - EPSI Grenoble 2024-2025**

## ‚ú® Overview
This project aims to predict the results of French elections by department using machine learning techniques. The goal is not only to predict but to build a **robust and reproducible data pipeline** that feeds an **interactive dashboard** for visualizing historical results and future predictions.

**Key Results:** Random Forest model achieving 48.94% accuracy with predictions for 94 French departments in 2027.

## üöÄ Our Workflow Pipeline
The project is structured around three sequential Jupyter notebooks that form a complete and automated pipeline, from raw data to the final result.

1.  `notebooks/data_preprocessing.ipynb`
    *   **Role:** Prepares and cleans the data.
    *   **Actions:**
        *   Aggregates raw data from various CSV files.
        *   Loads the data into a PostgreSQL database.
        *   Performs a temporal split (train < 2024, test = 2024).
        *   Saves the processed datasets and transformation tools (`preprocessor`, `label_encoder`).

2.  `notebooks/model_training.ipynb`
    *   **Role:** Trains and selects the best model.
    *   **Actions:**
        *   Tests several algorithms (Random Forest, Decision Tree, Logistic Regression, SVM).
        *   Evaluates them on the 2024 test set.
        *   **Best model: Random Forest with 48.94% accuracy.**
        *   **Automatically saves the best-performing model.**

3.  `notebooks/prediction.ipynb`
    *   **Role:** Generates final predictions and prepares data for BI.
    *   **Actions:**
        *   Loads the best model.
        *   **Generates 94 predictions for all French departments in 2027.**
        *   Creates a final table, `election_results_for_bi`, in the database, combining all historical and future results for easy analysis.

## üìä Visualization with the Dashboard
Once the data pipeline has been executed, a Streamlit dashboard is available to explore the results. It allows you to:
-   Visualize the winning parties by department on an interactive map of France.
-   Filter results by year, including **predictions for 2027**.
-   View aggregated statistics and detailed data for each year.

## üìÇ File Structure
```
.
‚îú‚îÄ‚îÄ assets/                 # Project assets (images, diagrams)
‚îú‚îÄ‚îÄ data/                   # Raw datasets (.csv, .geojson)
‚îú‚îÄ‚îÄ database/               # Saved processing artifacts
‚îÇ   ‚îú‚îÄ‚îÄ preprocessor_X.joblib # Saved data transformation tool
‚îÇ   ‚îî‚îÄ‚îÄ label_encoder_y.joblib  # Saved target encoder
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ random_forest_predictor.joblib # Best saved prediction model
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.ipynb   # Notebook for data prep
‚îÇ   ‚îú‚îÄ‚îÄ model_training.ipynb     # Notebook for model training
‚îÇ   ‚îî‚îÄ‚îÄ prediction.ipynb         # Notebook for generating predictions
‚îú‚îÄ‚îÄ streamlit/
‚îÇ   ‚îî‚îÄ‚îÄ dashboard.py      # Code for the interactive dashboard
‚îú‚îÄ‚îÄ .env.example          # Example file for environment variables
‚îú‚îÄ‚îÄ .env                  # Configuration file (ignored by git)
‚îú‚îÄ‚îÄ .gitignore            # Files and directories ignored by git
‚îú‚îÄ‚îÄ Dockerfile            # Defines the application's environment
‚îú‚îÄ‚îÄ docker-compose.yml    # Orchestrates Docker services
‚îú‚îÄ‚îÄ run_project.sh        # Execution script for the pipeline
‚îú‚îÄ‚îÄ README.md             # This file
‚îî‚îÄ‚îÄ requirements.txt      # Project dependencies
```

## üìä Data Used
Our dataset includes:
- **Historical electoral results** (2017-2024): turnout, registered voters, votes per party
- **Socio-economic indicators**: unemployment rate, poverty rate  
- **Social data**: crime statistics (victims count), immigration rate
- **Total**: 752 samples across 94 French departments

## üê≥ Installation and Launch

### Prerequisites
- [Docker](https://www.docker.com/get-started) & [Docker Compose](https://docs.docker.com/compose/install/)

### Step 1: Run the Data Pipeline
This step uses Docker to create the database, process the data, and train the model.
1.  **Clone the repository** and navigate into the project folder.
2.  **Configure your environment:**
    -   Create a `.env` file by copying the `.env.example` template.
    -   Fill in the environment variables (`PG_USER`, `PG_PASSWORD`, `PG_DBNAME`, `PG_PORT`).
3.  **Launch the project:**
    -   Open a terminal at the project root and run the following command:
      ```bash
      docker-compose up --build
      ```
    -   This single command will build and start the containers. The `run_project.sh` script will automatically execute to run the entire data pipeline.
    -   **Keep this terminal open.**

### Step 2: Launch the Interactive Dashboard
Once the pipeline in Step 1 is complete (you will see the logs of the notebook executions), you can launch the dashboard.
1.  **Install dependencies** (in a **new terminal**):
    -   It is recommended to create a Python virtual environment.
      ```bash
      python3 -m venv venv
      source venv/bin/activate  # On macOS/Linux
      # venv\Scripts\activate   # On Windows
      ```
    -   Install the required libraries:
      ```bash
      pip install -r requirements.txt
      ```
2.  **Launch the dashboard:**
    ```bash
    streamlit run streamlit/dashboard.py
    ```
    -   The dashboard will be accessible in your browser at the address indicated (usually `http://localhost:8501`).

### Stopping the Services
-   To stop the dashboard, press `Ctrl + C` in its terminal.
-   To stop the database and application containers, go back to the Docker terminal, press `Ctrl + C`, and then run:
      ```bash
      docker-compose down
      ```

## üìÑ License
This project is licensed under the terms of the LICENSE file.

## üë• The Team
- [@hicham](https://github.com/spideystreet)
- [@amine](https://github.com/testt753)
- [@wassim](https://github.com/Wassim38)

## üí¨ Feedback
Have suggestions or questions? Feel free to open an issue or contact us directly! 