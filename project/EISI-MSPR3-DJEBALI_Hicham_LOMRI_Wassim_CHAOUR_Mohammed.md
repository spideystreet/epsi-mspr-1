# Pr√©diction des R√©sultats √âlectoraux par D√©partement : Pipeline de Machine Learning et Tableau de Bord Interactif

**Projet MSPR - TPRE813**  
**Master 1 EISI - EPSI Grenoble**  
**Ann√©e acad√©mique 2024-2025**

---

**Auteurs :**
- HICHAM [@spideystreet](https://github.com/spideystreet)
- AMINE [@testt753](https://github.com/testt753)  
- WASSIM [@Wassim38](https://github.com/Wassim38)

**Encadrement :** [Mohamed Mechri]  
**Date de soutenance :** [11 Juillet 2025]

---

## Table des Mati√®res

1. [R√©sum√© Ex√©cutif](#1-r√©sum√©-ex√©cutif)
2. [Introduction et Contexte](#2-introduction-et-contexte)
3. [Revue de Litt√©rature](#3-revue-de-litt√©rature)
4. [M√©thodologie](#4-m√©thodologie)
5. [Architecture Technique](#5-architecture-technique)
6. [Collecte et Pr√©paration des Donn√©es](#6-collecte-et-pr√©paration-des-donn√©es)
7. [Mod√©lisation et Machine Learning](#7-mod√©lisation-et-machine-learning)
8. [R√©sultats et √âvaluation](#8-r√©sultats-et-√©valuation)
9. [Interface Utilisateur et Visualisation](#9-interface-utilisateur-et-visualisation)
10. [D√©ploiement et Infrastructure](#10-d√©ploiement-et-infrastructure)
11. [Discussion et Limites](#11-discussion-et-limites)
12. [Conclusion et Perspectives](#12-conclusion-et-perspectives)
13. [R√©f√©rences](#13-r√©f√©rences)
14. [Annexes](#14-annexes)

---

## 1. R√©sum√© Ex√©cutif

### 1.1 Objectifs du Projet
Ce projet vise √† d√©velopper un syst√®me de pr√©diction des r√©sultats √©lectoraux fran√ßais par d√©partement, en s'appuyant sur des techniques de machine learning et des donn√©es socio-√©conomiques. L'objectif principal est de construire un pipeline de donn√©es robuste et reproductible alimentant un tableau de bord interactif pour la visualisation des r√©sultats historiques et des pr√©dictions futures.

### 1.2 Approche M√©thodologique
Notre approche repose sur trois piliers fondamentaux :
- **Pipeline de donn√©es automatis√©** : Traitement s√©quentiel via Jupyter notebooks
- **Mod√©lisation pr√©dictive** : Utilisation d'algorithmes de machine learning supervis√©
- **Interface de visualisation** : Tableau de bord interactif d√©velopp√© avec Streamlit

### 1.3 R√©sultats Principaux
- D√©veloppement d'un pipeline complet de traitement des donn√©es √©lectorales
- Cr√©ation d'un mod√®le pr√©dictif Random Forest avec une pr√©cision de **48,94%** sur les donn√©es de test 2024
- D√©ploiement d'une interface web interactive permettant la visualisation des pr√©dictions pour 2027
- G√©n√©ration de **94 pr√©dictions d√©partementales** pour l'ann√©e 2027

```mermaid
graph TD
    A["üèõÔ∏è Government APIs<br/>data.gouv.fr"] --> B["üìä Raw Data Collection<br/>Elections, Crime, Employment, Immigration"]
    B --> C["üîß Dataiku Preprocessing<br/>Cleaning & Normalization"]
    C --> D["üê≥ Docker Environment<br/>PostgreSQL + Python"]
    
    D --> E["üìì Notebook 1<br/>data_preprocessing.ipynb"]
    E --> F["üóÑÔ∏è PostgreSQL Database<br/>Structured Tables + Views"]
    
    F --> G["üìì Notebook 2<br/>model_training.ipynb"]
    G --> H["ü§ñ ML Models<br/>Random Forest, GB, LR"]
    H --> I["üíæ Best Model<br/>Joblib Persistence"]
    
    I --> J["üìì Notebook 3<br/>prediction.ipynb"]
    J --> K["üîÆ 2027 Predictions<br/>election_results_for_bi"]
    
    K --> L["üåê Streamlit Dashboard<br/>Interactive Visualization"]
    L --> M["üë§ End User<br/>Electoral Analysis"]
    
    style A fill:#e1f5fe
    style L fill:#f3e5f5
    style M fill:#e8f5e8
```

---

## 2. Introduction et Contexte

### 2.1 Probl√©matique
L'analyse et la pr√©diction des comportements √©lectoraux constituent un enjeu majeur pour la compr√©hension des dynamiques politiques contemporaines. Dans un contexte o√π les donn√©es ouvertes gouvernementales fran√ßaises offrent une richesse d'informations in√©dite, il devient possible de d√©velopper des mod√®les pr√©dictifs sophistiqu√©s combinant variables √©lectorales et indicateurs socio-√©conomiques.

### 2.2 Enjeux Techniques et Scientifiques
Ce projet s'inscrit dans la convergence de plusieurs domaines :
- **Science des donn√©es** : Extraction, transformation et analyse de grandes quantit√©s de donn√©es
- **Machine Learning** : Application d'algorithmes pr√©dictifs √† des donn√©es temporelles
- **Ing√©nierie logicielle** : D√©veloppement d'un pipeline reproductible et scalable
- **Visualisation de donn√©es** : Cr√©ation d'interfaces intuitives pour l'exploration des r√©sultats

### 2.3 Objectifs Acad√©miques
Dans le cadre du Master EISI √† EPSI Grenoble, ce projet permet de d√©montrer :
- La ma√Ætrise des technologies de containerisation (Docker)
- L'application pratique des techniques de machine learning
- Le d√©veloppement d'applications web interactives
- La gestion de projets informatiques complexes

```mermaid
graph LR
    subgraph "Data Sources"
        A1["Elections Data<br/>2017-2024"]
        A2["Crime Statistics<br/>Victims Count"]
        A3["Employment Data<br/>Unemployment Rate"]
        A4["Immigration Data<br/>Immigration Rate"]
        A5["Poverty Data<br/>Poverty Rate"]
    end
    
    subgraph "Database Layer"
        B1["election_data"]
        B2["crime_data"]
        B3["unemployment_data"]
        B4["immigration_data"]
        B5["poverty_data"]
        B6["elections_all VIEW"]
    end
    
    subgraph "ML Pipeline"
        C1["Feature Engineering<br/>StandardScaler + OneHot"]
        C2["Train/Test Split<br/>2017-2023 / 2024"]
        C3["Model Training<br/>Random Forest"]
        C4["Model Evaluation<br/>F1-Score, Accuracy"]
    end
    
    subgraph "Prediction & Viz"
        D1["2027 Predictions"]
        D2["Interactive Map"]
        D3["Statistical Dashboard"]
    end
    
    A1 --> B1
    A2 --> B2
    A3 --> B3
    A4 --> B4
    A5 --> B5
    
    B1 --> B6
    B2 --> B6
    B3 --> B6
    B4 --> B6
    B5 --> B6
    
    B6 --> C1
    C1 --> C2
    C2 --> C3
    C3 --> C4
    
    C3 --> D1
    D1 --> D2
    D1 --> D3
    
    style B6 fill:#fff2cc
    style C3 fill:#d5e8d4
    style D1 fill:#f8cecc
```

---

## 3. Revue de Litt√©rature

### 3.1 Pr√©diction √âlectorale et Machine Learning
Les travaux acad√©miques r√©cents montrent l'efficacit√© des approches de machine learning pour la pr√©diction √©lectorale. Silver (2016) d√©montre l'importance de la combinaison de multiples sources de donn√©es, tandis que Wang et al. (2018) explorent l'utilisation des algorithmes d'ensemble pour am√©liorer la pr√©cision pr√©dictive.

### 3.2 Variables Socio-√©conomiques et Comportement √âlectoral
La litt√©rature √©tablit des corr√©lations significatives entre indicateurs socio-√©conomiques et choix √©lectoraux :
- **Ch√¥mage** : Impact direct sur les votes protestataires (Hern√°ndez & Kriesi, 2016)
- **Immigration** : Influence sur les votes d'extr√™me droite (Lubbers & Scheepers, 2017)
- **Criminalit√©** : Corr√©lation avec les pr√©occupations s√©curitaires (Green & McFarlane, 2016)

### 3.3 Technologies de Pipeline de Donn√©es
L'√©mergence des pratiques MLOps (Machine Learning Operations) souligne l'importance des pipelines automatis√©s pour la reproductibilit√© des mod√®les (Sculley et al., 2015).

---

## 4. M√©thodologie

### 4.1 Approche G√©n√©rale
Notre m√©thodologie suit le cycle de vie standard des projets de data science, adapt√© aux sp√©cificit√©s de la pr√©diction √©lectorale :

1. **D√©finition du probl√®me** : Pr√©diction binaire/multiclasse des partis gagnants
2. **Collecte des donn√©es** : Agr√©gation de sources gouvernementales fran√ßaises
3. **Exploration et pr√©paration** : Nettoyage et ing√©nierie des features
4. **Mod√©lisation** : Entra√Ænement et s√©lection d'algorithmes
5. **√âvaluation** : Validation sur donn√©es de test temporelles
6. **D√©ploiement** : Interface utilisateur et visualisation

```mermaid
graph TD
    A["üì• Data Collection<br/>Government APIs"] --> B["üîß Data Preprocessing<br/>Dataiku Platform"]
    B --> C["üßπ Data Cleaning<br/>Missing Values, Outliers"]
    C --> D["üîÑ Data Integration<br/>PostgreSQL Database"]
    D --> E["‚öôÔ∏è Feature Engineering<br/>Encoding, Scaling"]
    E --> F["üìä Exploratory Analysis<br/>Statistics, Distributions"]
    F --> G["ü§ñ Model Training<br/>Multiple Algorithms"]
    G --> H["üìà Model Evaluation<br/>Validation Metrics"]
    H --> I{"Best Model?"}
    I -->|No| G
    I -->|Yes| J["üíæ Model Persistence<br/>Joblib Storage"]
    J --> K["üîÆ Future Predictions<br/>2027 Electoral Map"]
    K --> L["üåê Dashboard Development<br/>Streamlit Interface"]
    L --> M["üöÄ Deployment<br/>Docker Containers"]
    M --> N["‚úÖ Final Validation<br/>User Testing"]
    
    style A fill:#e1f5fe
    style G fill:#f3e5f5
    style J fill:#e8f5e8
    style L fill:#fff3e0
```

### 4.2 Division Temporelle
Approche de validation temporelle rigoureuse :
- **Donn√©es d'entra√Ænement** : 2017-2023 (652 √©chantillons)
- **Donn√©es de test** : 2024 (94 √©chantillons)
- **Pr√©dictions** : 2027 (projection future)

### 4.3 Crit√®res d'√âvaluation
- **Pr√©cision globale** : Pourcentage de pr√©dictions correctes
- **F1-Score** : Mesure √©quilibr√©e pour classes d√©s√©quilibr√©es
- **Matrice de confusion** : Analyse d√©taill√©e des erreurs par parti

---

## 5. Architecture Technique

### 5.1 Vue d'Ensemble de l'Architecture
L'architecture du syst√®me repose sur une approche modulaire et containeris√©e, garantissant la reproductibilit√© et la scalabilit√©.

```mermaid
graph TB
    subgraph "Container: PostgreSQL DB"
        DB["üóÑÔ∏è PostgreSQL 13<br/>Port: 5432<br/>Data Persistence"]
    end
    
    subgraph "Container: Python Application"
        APP["üêç Python 3.11<br/>Jupyter + ML Libraries<br/>Pipeline Execution"]
    end
    
    subgraph "Host System"
        DASHBOARD["üåê Streamlit Dashboard<br/>Port: 8501<br/>Interactive UI"]
        USER["üë§ User Browser<br/>http://localhost:8501"]
    end
    
    subgraph "Data Flow"
        CSV["üìÑ CSV Files<br/>/data directory"]
        MODELS["ü§ñ Trained Models<br/>/models directory"]
        ARTIFACTS["üíæ ML Artifacts<br/>/database directory"]
    end
    
    APP --> DB
    DB --> APP
    CSV --> APP
    APP --> MODELS
    APP --> ARTIFACTS
    
    DB --> DASHBOARD
    MODELS --> DASHBOARD
    DASHBOARD --> USER
    
    style DB fill:#e3f2fd
    style APP fill:#f3e5f5
    style DASHBOARD fill:#e8f5e8
    style USER fill:#fff3e0
```

### 5.2 Composants Principaux

#### 5.2.1 Pipeline de Donn√©es
- **Notebooks Jupyter** : Traitement s√©quentiel automatis√©
- **PostgreSQL** : Base de donn√©es relationnelle pour stockage structur√©
- **Docker Compose** : Orchestration des services

#### 5.2.2 Stack Technologique
```
Backend:
‚îú‚îÄ‚îÄ Python 3.11
‚îú‚îÄ‚îÄ PostgreSQL 13
‚îú‚îÄ‚îÄ Jupyter
‚îú‚îÄ‚îÄ Scikit-learn
‚îú‚îÄ‚îÄ Pandas/NumPy
‚îî‚îÄ‚îÄ SQLAlchemy

Frontend:
‚îú‚îÄ‚îÄ Streamlit
‚îú‚îÄ‚îÄ Plotly
‚îú‚îÄ‚îÄ Folium (cartes interactives)
‚îî‚îÄ‚îÄ Bootstrap (styling)

Infrastructure:
‚îú‚îÄ‚îÄ Docker & Docker Compose
‚îú‚îÄ‚îÄ Git (versioning)
‚îî‚îÄ‚îÄ Joblib (persistance mod√®les)
```

### 5.3 Flux de Donn√©es
Le flux de donn√©es suit une architecture ETL (Extract, Transform, Load) rigoureuse :

1. **Extraction** : APIs gouvernementales ‚Üí Fichiers CSV locaux
2. **Transformation** : Notebooks Jupyter ‚Üí Donn√©es nettoy√©es
3. **Chargement** : PostgreSQL ‚Üí Tables relationnelles
4. **Mod√©lisation** : Scikit-learn ‚Üí Mod√®les persist√©s
5. **Visualisation** : Streamlit ‚Üí Interface utilisateur

```mermaid
graph LR
    subgraph "Input Features"
        F1["Department Code<br/>01, 02, 03..."]
        F2["Year<br/>2017-2024"]
        F3["Unemployment Rate<br/>%"]
        F4["Crime Victims<br/>Count"]
        F5["Immigration Rate<br/>%"]
        F6["Poverty Rate<br/>%"]
    end
    
    subgraph "Preprocessing"
        P1["OneHot Encoder<br/>Categorical"]
        P2["Standard Scaler<br/>Numerical"]
    end
    
    subgraph "Random Forest Model"
        RF["üå≤ Random Forest<br/>n_estimators=100<br/>max_depth=10"]
    end
    
    subgraph "Output"
        O1["Winning Party<br/>RN, LR, PS, LFI, Others"]
        O2["Probability Scores<br/>Confidence Levels"]
    end
    
    F1 --> P1
    F2 --> P1
    F3 --> P2
    F4 --> P2
    F5 --> P2
    F6 --> P2
    
    P1 --> RF
    P2 --> RF
    
    RF --> O1
    RF --> O2
    
    style RF fill:#d5e8d4
    style O1 fill:#f8cecc
```

---

## 6. Collecte et Pr√©paration des Donn√©es

### 6.1 Sources de Donn√©es

Notre jeu de donn√©es combine plusieurs sources officielles fran√ßaises :

#### 6.1.1 Donn√©es √âlectorales
- **Source** : [data.gouv.fr - Donn√©es des √©lections](https://www.data.gouv.fr/fr/pages/donnees-des-elections/)
- **P√©riode** : 2017-2024
- **Variables** : Nombre d'inscrits, votants, r√©sultats par parti
- **Granularit√©** : D√©partementale

#### 6.1.2 Donn√©es Socio-√©conomiques
- **Emploi** : [data.gouv.fr - Donn√©es emploi](https://www.data.gouv.fr/fr/pages/donnees-emploi/)
- **S√©curit√©** : [data.gouv.fr - Donn√©es s√©curit√©](https://www.data.gouv.fr/fr/pages/donnees-securite/)
- **D√©mographie** : [INSEE](https://www.data.gouv.fr/fr/organizations/institut-national-de-la-statistique-et-des-etudeseconomiques-insee/)

### 6.2 Pr√©traitement avec Dataiku
Phase initiale de nettoyage r√©alis√©e sur la plateforme Dataiku :
- **Normalisation** des formats de dates
- **Harmonisation** des codes d√©partementaux
- **D√©tection et traitement** des valeurs aberrantes
- **Standardisation** des noms de colonnes

![Processus de Pr√©traitement](../assets/images/dataiku_pipeline_real.png)

### 6.3 Pipeline de Traitement Automatis√©

#### 6.3.1 Notebook 1 : data_preprocessing.ipynb
```python
# Chargement et int√©gration des donn√©es
TABLE_CONFIG = {
    "unemployment_data": {...},
    "crime_data": {...},
    "election_data": {...},
    "immigration_data": {...},
    "poverty_data": {...}
}

# Cr√©ation de la vue unifi√©e
CREATE VIEW elections_all AS
SELECT ed."YEAR", ed."DEPARTMENT_CODE", ed."WINNER",
       cd."NUMBER_OF_VICTIMS", id."IMMIGRATION_RATE",
       pd."POVERTY_RATE", ud."UNEMPLOYMENT_RATE"
FROM election_data ed
LEFT JOIN crime_data cd ON ...
```

#### 6.3.2 Gestion des Valeurs Manquantes
Strat√©gie d'imputation progressive :
- **Forward Fill** par d√©partement pour continuit√© temporelle
- **Suppression** des lignes sans variable cible
- **Validation** de l'int√©grit√© finale (0 valeurs nulles d√©tect√©es)

### 6.4 R√©sultats du Pr√©traitement

| Statistique | Valeur |
|-------------|--------|
| **√âchantillons totaux** | 752 lignes |
| **√âchantillons d'entra√Ænement** | 652 lignes (2017-2023) |
| **√âchantillons de test** | 94 lignes (2024) |
| **Features num√©riques** | 4 (taux ch√¥mage, immigration, pauvret√©, victimes) |
| **Features cat√©gorielles** | 1 (code d√©partement) |
| **Valeurs manquantes** | 0 (apr√®s imputation) |

---

## 7. Mod√©lisation et Machine Learning

### 7.1 Pr√©paration des Features

#### 7.1.1 Encodage des Variables
```python
# Configuration du pr√©processeur
preprocessor = ColumnTransformer([
    ('num', StandardScaler(), numerical_features),
    ('cat', OneHotEncoder(), categorical_features)
])

# Encodage de la variable cible
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y_train)
```

#### 7.1.2 Variables Explicatives
- **Variables num√©riques** : Taux de ch√¥mage, immigration, pauvret√©, nombre de victimes
- **Variables cat√©gorielles** : Code d√©partement (OneHot encod√© en 95 features)
- **Variable cible** : Parti gagnant (5 classes : DROITE, PS, RN, LFI, GAUCHE)

### 7.2 Algorithmes Test√©s et Performances

#### 7.2.1 Comparaison des Mod√®les
Quatre algorithmes ont √©t√© entra√Æn√©s et √©valu√©s :

| Mod√®le | Accuracy | Weighted Precision | Rang |
|--------|----------|-------------------|------|
| **Random Forest** | **48.94%** | **66.34%** | ü•á |
| Decision Tree | 44.68% | 60.25% | ü•à |
| Logistic Regression | 29.79% | 62.13% | ü•â |
| SVM | 23.40% | 62.98% | 4 |

#### 7.2.2 Mod√®le S√©lectionn√© : Random Forest
```python
rf_model = RandomForestClassifier(
    n_estimators=100,
    random_state=42
)
```

**Avantages du Random Forest** :
- **Meilleure performance** : 48.94% d'accuracy
- **Robustesse aux outliers**
- **Gestion native des variables mixtes**
- **Interpr√©tabilit√©** via importance des features

### 7.3 Entra√Ænement et Validation

#### 7.3.1 Protocole d'√âvaluation
- **Validation temporelle** : Train sur 2017-2023, test sur 2024
- **M√©triques** : Accuracy, Weighted Precision
- **Persistance** : Sauvegarde du meilleur mod√®le en `random_forest_predictor.joblib`

#### 7.3.2 Architecture des Features
Apr√®s preprocessing, le mod√®le utilise **99 features** :
- 4 features num√©riques standardis√©es
- 95 features cat√©gorielles (OneHot encoding des d√©partements)

![Comparaison des Mod√®les](../assets/images/model_comparison_chart.png)

---

## 8. R√©sultats et √âvaluation

### 8.1 Performance du Mod√®le Random Forest

#### 8.1.1 M√©triques Globales
- **Pr√©cision globale** : **48.94%** sur le jeu de test 2024
- **Weighted Precision** : **66.34%**
- **Nombre de pr√©dictions correctes** : 46/94 d√©partements

#### 8.1.2 Analyse de Performance
Le mod√®le Random Forest montre des performances mod√©r√©es mais coh√©rentes :
- **Sup√©riorit√© claire** par rapport aux autres algorithmes test√©s
- **Robustesse** face √† la complexit√© des donn√©es √©lectorales
- **Capacit√© de g√©n√©ralisation** sur donn√©es temporelles futures

### 8.2 Pr√©dictions 2027

#### 8.2.1 G√©n√©ration des Pr√©dictions
- **Base de donn√©es** : Utilisation des donn√©es 2024 comme r√©f√©rence
- **Pr√©dictions g√©n√©r√©es** : 94 d√©partements fran√ßais
- **Consolidation** : 375 lignes totales (historique + pr√©dictions)

#### 8.2.2 Pipeline de Pr√©diction
```python
# Preprocessing des donn√©es 2024 pour pr√©diction 2027
X_processed = preprocessor_X.transform(features_to_predict)
predictions_encoded = model.predict(X_processed)
predictions_decoded = label_encoder_y.inverse_transform(predictions_encoded)
```

#### 8.2.3 Int√©gration Business Intelligence
- **Vue consolid√©e** : `election_data_for_bi` cr√©√©e dans PostgreSQL
- **Donn√©es historiques** : 281 lignes (2017-2024)
- **Pr√©dictions futures** : 94 lignes (2027)
- **P√©riode totale** : 2017-2027 (11 ann√©es)

![Pr√©dictions 2027 Map](../assets/images/predictions_2027_map.png)

### 8.3 Analyse des Limites

#### 8.3.1 Performance Mod√©r√©e
L'accuracy de 48.94% s'explique par :
- **Complexit√© intrins√®que** des ph√©nom√®nes √©lectoraux
- **Variables manquantes** (r√©seaux sociaux, √©v√©nements conjoncturels)
- **Simplification** des dynamiques politiques locales

#### 8.3.2 Points d'Am√©lioration Identifi√©s
- **Enrichissement des donn√©es** : Int√©gration de nouvelles sources
- **Feature engineering** : Cr√©ation de variables composites
- **Ensemble methods** : Combinaison de plusieurs mod√®les

---

## 9. Interface Utilisateur et Visualisation

### 9.1 Architecture du Dashboard Streamlit

Le tableau de bord interactif offre une exploration intuitive des donn√©es et pr√©dictions :

```python
# Structure principale du dashboard
def main():
    st.title("üó≥Ô∏è Pr√©dicteur Electoral France")
    
    # Sidebar pour filtres
    year_filter = st.sidebar.selectbox("Ann√©e", options)
    
    # Visualisations principales
    display_map(filtered_data)
    display_statistics(filtered_data)
    display_predictions(model_results)
```

### 9.2 Fonctionnalit√©s Principales

#### 9.2.1 Carte Interactive
- **Technologie** : Folium + Streamlit
- **Features** :
  - Visualisation par d√©partement
  - Code couleur par parti gagnant
  - Tooltips avec donn√©es d√©taill√©es
  - Zoom et navigation interactifs

#### 9.2.2 Filtres Temporels
- **Ann√©es historiques** : 2017-2024
- **Pr√©dictions** : 2027
- **Comparaisons** : √âvolution temporelle

#### 9.2.3 Statistiques Agr√©g√©es
- **Graphiques en barres** : R√©partition nationale
- **Tableaux d√©taill√©s** : Donn√©es par d√©partement
- **M√©triques cl√©s** : Participation, margins

![Interface Dashboard](../assets/images/dashboard_main_interface.png)

### 9.3 Experience Utilisateur

#### 9.3.1 Design Responsif
- **Layout adaptatif** : Desktop et mobile
- **Th√®me moderne** : Bootstrap styling
- **Navigation intuitive** : Menu lat√©ral

#### 9.3.2 Performance
- **Chargement optimis√©** : Cache Streamlit
- **Requ√™tes efficaces** : Indexation PostgreSQL
- **Mise √† jour temps r√©el** : Connexion directe DB

---

## 10. D√©ploiement et Infrastructure

### 10.1 Containerisation Docker

#### 10.1.1 Architecture Multi-Conteneurs
```yaml
# docker-compose.yml
services:
  db:
    image: postgres:13
    environment:
      - POSTGRES_USER=${PG_USER}
      - POSTGRES_PASSWORD=${PG_PASSWORD}
  
  app:
    build: .
    depends_on:
      - db
    volumes:
      - .:/app
```

#### 10.1.2 Pipeline d'Ex√©cution
```bash
#!/bin/bash
# run_project.sh

echo "STEP 1: Data Preprocessing..."
jupyter nbconvert --execute notebooks/data_preprocessing.ipynb

echo "STEP 2: Model Training..."
jupyter nbconvert --execute notebooks/model_training.ipynb

echo "STEP 3: Predictions..."
jupyter nbconvert --execute notebooks/prediction.ipynb
```

### 10.2 Reproductibilit√©

#### 10.2.1 Gestion des D√©pendances
```txt
# requirements.txt
streamlit==1.28.0
pandas==2.0.3
scikit-learn==1.3.0
psycopg2-binary==2.9.7
folium==0.14.0
plotly==5.15.0
```

#### 10.2.2 Variables d'Environnement
```env
# .env
PG_USER=postgres
PG_PASSWORD=secure_password
PG_HOST=localhost
PG_PORT=5432
PG_DBNAME=elections
```

### 10.3 D√©ploiement Production

#### 10.3.1 Options de D√©ploiement
- **Local** : Docker Compose (d√©veloppement)
- **Cloud** : Streamlit Cloud, Heroku, Railway
- **Enterprise** : Kubernetes, AWS ECS

#### 10.3.2 Monitoring et Maintenance
- **Logs** : Centralis√©s via Docker
- **Backup** : PostgreSQL dump automatique
- **Updates** : Pipeline CI/CD potentiel

```mermaid
graph TB
    subgraph "üè† Local Development Environment"
        subgraph "üì± User Interface"
            BROWSER["üåê Web Browser<br/>http://localhost:8501"]
            USER["üë§ Data Scientist / Analyst"]
        end
        
        subgraph "üê≥ Docker Compose Services"
            direction TB
            DB_CONTAINER["üóÑÔ∏è PostgreSQL Container<br/>postgres:13<br/>Port: 5432<br/>Volume: db_data"]
            APP_CONTAINER["üêç Python App Container<br/>Python 3.11 + Jupyter<br/>Notebooks Execution"]
        end
        
        subgraph "üìÅ Local File System"
            DATA_FILES["üìÑ CSV Data Files<br/>/data/"]
            MODELS["ü§ñ ML Models<br/>/models/"]
            ARTIFACTS["üíæ Preprocessors<br/>/database/"]
            NOTEBOOKS["üìì Jupyter Notebooks<br/>/notebooks/"]
        end
        
        subgraph "üöÄ Streamlit Application"
            STREAMLIT["üåü Streamlit Dashboard<br/>Port: 8501<br/>Interactive UI"]
        end
    end
    
    subgraph "‚òÅÔ∏è Production Options"
        CLOUD_OPTIONS["üåê Cloud Deployment<br/>‚Ä¢ Streamlit Cloud<br/>‚Ä¢ Heroku<br/>‚Ä¢ Railway<br/>‚Ä¢ AWS ECS"]
    end
    
    %% User interactions
    USER --> BROWSER
    BROWSER --> STREAMLIT
    
    %% Docker internal communications
    APP_CONTAINER <--> DB_CONTAINER
    APP_CONTAINER --> DATA_FILES
    APP_CONTAINER --> MODELS
    APP_CONTAINER --> ARTIFACTS
    APP_CONTAINER --> NOTEBOOKS
    
    %% Streamlit connections
    STREAMLIT --> DB_CONTAINER
    STREAMLIT --> MODELS
    STREAMLIT --> DATA_FILES
    
    %% Deployment path
    STREAMLIT -.-> CLOUD_OPTIONS
    
    style DB_CONTAINER fill:#e3f2fd
    style APP_CONTAINER fill:#f3e5f5
    style STREAMLIT fill:#e8f5e8
    style BROWSER fill:#fff3e0
    style USER fill:#f0f4c3
    style CLOUD_OPTIONS fill:#fce4ec
```

---

## 11. Discussion et Limites

### 11.1 Forces du Projet

#### 11.1.1 Reproductibilit√©
- **Pipeline automatis√©** : Notebooks s√©quentiels
- **Containerisation** : Environnement isol√©
- **Documentation** : Code comment√© et structur√©

#### 11.1.2 Scalabilit√©
- **Architecture modulaire** : Composants ind√©pendants
- **Base de donn√©es** : PostgreSQL performant
- **Interface web** : Streamlit responsive

### 11.2 Limitations Identifi√©es

#### 11.2.1 Donn√©es
- **Granularit√© temporelle** : Donn√©es annuelles uniquement
- **Variables manquantes** : Certains indicateurs sociaux indisponibles
- **Biais g√©ographique** : Surrepr√©sentation de certaines r√©gions

#### 11.2.2 Mod√©lisation
- **Performance mod√©r√©e** : 48.94% d'accuracy
- **Complexit√© √©lectorale** : R√©duction √† des variables quantitatives
- **√âv√©nements exceptionnels** : Difficile √† pr√©dire (crises, scandales)
- **Dynamiques locales** : Variables non captur√©es

#### 11.2.3 Techniques
- **Validation temporelle** : Un seul point de test (2024)
- **Features engineering** : Potentiel d'am√©lioration
- **Ensembling** : Combinaison de mod√®les non explor√©e

### 11.3 Biais et Consid√©rations √âthiques

#### 11.3.1 Biais de S√©lection
- **Sources de donn√©es** : Limit√©es aux donn√©es publiques
- **P√©riode d'√©tude** : 2017-2024, √©volutions r√©centes

#### 11.3.2 Implications √âthiques
- **Influence d√©mocratique** : Risque de proph√©tie auto-r√©alisatrice
- **Transparence** : N√©cessit√© d'explicabilit√© des pr√©dictions
- **Usage responsable** : Cadre d'utilisation d√©fini

---

## 12. Conclusion et Perspectives

### 12.1 Synth√®se des R√©alisations

Ce projet a permis de d√©velopper avec succ√®s un syst√®me complet de pr√©diction √©lectorale, d√©montrant :

#### 12.1.1 Objectifs Atteints
- ‚úÖ **Pipeline automatis√©** : Traitement de bout en bout des donn√©es
- ‚úÖ **Mod√®le pr√©dictif** : Pr√©cision de 48.94% sur donn√©es 2024
- ‚úÖ **Interface utilisateur** : Dashboard interactif fonctionnel
- ‚úÖ **Infrastructure** : D√©ploiement containeris√© reproductible
- ‚úÖ **Pr√©dictions 2027** : 94 pr√©dictions d√©partementales g√©n√©r√©es

#### 12.1.2 Comp√©tences D√©velopp√©es
- **Data Engineering** : ETL, bases de donn√©es, APIs
- **Machine Learning** : Preprocessing, modeling, evaluation
- **DevOps** : Docker, containerisation, orchestration
- **Full-Stack Development** : Backend Python, Frontend Streamlit

### 12.2 Perspectives d'Am√©lioration

#### 12.2.1 Court Terme
- **Optimisation mod√®le** : Hyperparameter tuning pour am√©liorer les 48.94%
- **Enrichissement des donn√©es** : R√©seaux sociaux, sondages
- **Interface utilisateur** : UX am√©lior√©e, nouvelles visualisations

#### 12.2.2 Moyen Terme
- **Temps r√©el** : Int√©gration de donn√©es dynamiques
- **Multi-√©chelle** : Pr√©dictions communales et r√©gionales
- **API REST** : Service de pr√©diction externalis√©

#### 12.2.3 Long Terme
- **Deep Learning** : R√©seaux de neurones pour patterns complexes
- **NLP** : Analyse de sentiment des discours politiques
- **Syst√®mes multi-agents** : Mod√©lisation des interactions √©lectorales

### 12.3 Impact Acad√©mique et Professionnel

#### 12.3.1 Contribution Acad√©mique
- **M√©thodologie reproductible** : Open source disponible
- **Cas d'√©tude** : Pipeline MLOps complet
- **Documentation** : Ressource p√©dagogique

#### 12.3.2 Pr√©paration Professionnelle
- **Portfolio technique** : D√©monstration de comp√©tences
- **Exp√©rience projet** : Gestion compl√®te de A √† Z
- **Technologies actuelles** : Stack moderne et demand√©e

---

## 13. Licence et Propri√©t√© Intellectuelle

### 13.1 Licence MIT
Ce projet est distribu√© sous licence MIT, garantissant une utilisation libre et ouverte :

```
MIT License

Copyright (c) 2024 HICHAM, AMINE, WASSIM - EPSI Grenoble

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

### 13.2 Avantages de la Licence MIT
- **Libert√© d'utilisation** : Utilisation libre pour projets commerciaux et non-commerciaux
- **Modification autoris√©e** : Adaptation et personnalisation du code
- **Distribution libre** : Partage sans restriction
- **Transparence** : Code source ouvert et auditable

### 13.3 Contributions Open Source
- **Repository GitHub** : Code source accessible publiquement
- **Documentation compl√®te** : Facilite la r√©utilisation et l'apprentissage
- **Reproductibilit√©** : Pipeline enti√®rement document√© et containeris√©
- **Impact p√©dagogique** : Ressource pour la communaut√© acad√©mique

### 13.4 Protection et Attribution
- **Attribution requise** : Mention des auteurs originaux obligatoire
- **Disclaimer** : Limitation de responsabilit√© clairement √©tablie
- **Copyright** : Droits d'auteur pr√©serv√©s pour les auteurs originaux

---

## 14. R√©f√©rences

### Articles Acad√©miques

1. Silver, N. (2016). *The Signal and the Noise: Why So Many Predictions Fail‚ÄîBut Some Don't*. Penguin Books.

2. Wang, W., Rothschild, D., Goel, S., & Gelman, A. (2018). Forecasting elections with non-representative polls. *International Journal of Forecasting*, 34(2), 183-194.

3. Hern√°ndez, E., & Kriesi, H. (2016). The electoral consequences of the financial and economic crisis in Europe. *European Journal of Political Research*, 55(2), 203-224.

4. Lubbers, M., & Scheepers, P. (2017). Explaining the growth of the radical right in Western Europe. *European Journal of Political Research*, 56(2), 365-390.

5. Sculley, D., et al. (2015). Hidden technical debt in machine learning systems. *Advances in Neural Information Processing Systems*, 28.

### Sources de Donn√©es

6. Data.gouv.fr. (2024). *Donn√©es des √©lections*. Retrieved from https://www.data.gouv.fr/fr/pages/donnees-des-elections/

7. Data.gouv.fr. (2024). *Donn√©es s√©curit√©*. Retrieved from https://www.data.gouv.fr/fr/pages/donnees-securite/

8. Data.gouv.fr. (2024). *Donn√©es emploi*. Retrieved from https://www.data.gouv.fr/fr/pages/donnees-emploi/

9. INSEE. (2024). *Institut National de la Statistique*. Retrieved from https://www.data.gouv.fr/fr/organizations/institut-national-de-la-statistique-et-des-etudeseconomiques-insee/

### Documentation Technique

10. Streamlit Documentation. (2024). *Building Data Apps*. Retrieved from https://docs.streamlit.io/

11. Scikit-learn Documentation. (2024). *Machine Learning in Python*. Retrieved from https://scikit-learn.org/

12. Docker Documentation. (2024). *Containerization Platform*. Retrieved from https://docs.docker.com/

---

## 15. Annexes

### Annexe A : Configuration Technique

#### A.1 Structure Compl√®te du Projet
```
epsi-mspr-1/
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îî‚îÄ‚îÄ images/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ 2017_2024_CHOMAGE_prepared.csv
‚îÇ   ‚îú‚îÄ‚îÄ 2017_2024_CRIMINALITE_prepared.csv
‚îÇ   ‚îú‚îÄ‚îÄ 2017_2024_ELECTIONS_prepared.csv
‚îÇ   ‚îú‚îÄ‚îÄ 2017_2024_IMMIGRATION_prepared.csv
‚îÇ   ‚îú‚îÄ‚îÄ 2017_2024_PAUVRETE_prepared.csv
‚îÇ   ‚îî‚îÄ‚îÄ departements.geojson
‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îú‚îÄ‚îÄ label_encoder_y.joblib
‚îÇ   ‚îî‚îÄ‚îÄ preprocessor_X.joblib
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ random_forest_predictor.joblib
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ model_training.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ prediction.ipynb
‚îú‚îÄ‚îÄ streamlit/
‚îÇ   ‚îî‚îÄ‚îÄ dashboard.py
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

#### A.2 Commandes d'Installation
```bash
# Clonage du projet
git clone [repository-url]
cd epsi-mspr-1

# Configuration environnement
cp .env.example .env
# √âditer .env avec vos param√®tres

# Lancement du pipeline
docker-compose up --build

# Lancement du dashboard (nouveau terminal)
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
streamlit run streamlit/dashboard.py
```

### Annexe B : Extraits de Code Cl√©s

#### B.1 Preprocessing Pipeline
```python
def create_elections_view(engine):
    """Cr√©ation de la vue agr√©g√©e elections_all"""
    create_view_query = """
    CREATE OR REPLACE VIEW elections_all AS
    SELECT
        ed."YEAR",
        ed."DEPARTMENT_CODE", 
        ed."WINNER",
        cd."NUMBER_OF_VICTIMS",
        id."IMMIGRATION_RATE",
        pd."POVERTY_RATE",
        ud."UNEMPLOYMENT_RATE"
    FROM election_data ed
    LEFT JOIN crime_data cd ON ed."DEPARTMENT_CODE" = cd."DEPARTMENT_CODE" 
                            AND ed."YEAR" = cd."YEAR"
    -- Additional joins...
    """
    
    with engine.connect() as connection:
        connection.execute(text(create_view_query))
        connection.commit()
```

#### B.2 Model Training
```python
def train_and_evaluate_models(X_train, X_test, y_train, y_test):
    """Entra√Ænement et √©valuation des mod√®les"""
    models = {
        'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),
        'GradientBoosting': GradientBoostingClassifier(random_state=42),
        'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000)
    }
    
    results = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        
        results[name] = {
            'accuracy': accuracy_score(y_test, y_pred),
            'f1_macro': f1_score(y_test, y_pred, average='macro'),
            'model': model
        }
    
    return results
```

#### B.3 Dashboard Visualization
```python
def create_france_map(data):
    """Cr√©ation de la carte interactive de France"""
    m = folium.Map(location=[46.603354, 1.888334], zoom_start=6)
    
    # Chargement des contours g√©ographiques
    with open('data/departements.geojson') as f:
        geojson_data = json.load(f)
    
    # Cr√©ation des couleurs par parti
    color_map = {
        'RN': 'darkblue',
        'LR': 'blue', 
        'PS': 'pink',
        'LFI': 'red',
        'Autres': 'gray'
    }
    
    folium.Choropleth(
        geo_data=geojson_data,
        data=data,
        columns=['DEPARTMENT_CODE', 'WINNER'],
        key_on='feature.properties.code',
        fill_color='Set3',
        legend_name='Parti Gagnant'
    ).add_to(m)
    
    return m
```

### Annexe C : M√©triques D√©taill√©es

#### C.1 R√©sultats de Performance des Mod√®les
| Mod√®le | Accuracy | Weighted Precision | Observations |
|--------|----------|-------------------|--------------|
| Random Forest | 48.94% | 66.34% | ‚úÖ Meilleure performance globale |
| Decision Tree | 44.68% | 60.25% | üî∂ Performance correcte |
| Logistic Regression | 29.79% | 62.13% | ‚ö†Ô∏è Sous-performance |
| SVM | 23.40% | 62.98% | ‚ùå Performance faible |

#### C.2 Statistiques du Dataset
| M√©trique | Valeur |
|----------|--------|
| **Total √©chantillons** | 752 |
| **Train set** | 652 √©chantillons |
| **Test set** | 94 √©chantillons |
| **Pr√©dictions 2027** | 94 d√©partements |
| **Consolidation BI** | 375 lignes totales |
| **P√©riode couverte** | 2017-2027 (11 ans) |

### Annexe D : Captures d'√âcran

![Interface Principale](../assets/images/dashboard_main_interface.png)
*Figure D.1 : Interface principale du dashboard avec carte interactive*

![Comparaison des Mod√®les](../assets/images/model_comparison_chart.png)
*Figure D.2 : Graphique de comparaison des performances des mod√®les*

![D√©tail D√©partement](../assets/images/dashboard_detail_view.png)
*Figure D.3 : Vue d√©taill√©e d'un d√©partement avec historique*

---

**Fin du Rapport**

*Ce document constitue le rapport acad√©mique complet du projet de pr√©diction √©lectorale d√©velopp√© dans le cadre du Master EISI √† EPSI Grenoble. L'ensemble du code source et des donn√©es sont disponibles sur le repository GitHub du projet.* 