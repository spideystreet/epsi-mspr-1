{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: Imports and Configuration\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DB_PATH = '../database/ELECTIONS.db'\n",
    "MODELS_DIR = '../models'\n",
    "PREPROCESSOR_PATH = '../database/preprocessor_X.joblib'\n",
    "LABEL_ENCODER_PATH = '../database/label_encoder_y.joblib'\n",
    "\n",
    "# Nom du meilleur modèle (doit correspondre au fichier sauvegardé à l'étape 1)\n",
    "BEST_MODEL_FILENAME = 'random_forest_predictor.joblib'\n",
    "MODEL_PATH = os.path.join(MODELS_DIR, BEST_MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and transformers...\n",
      "✅ Model 'random_forest_predictor.joblib' and transformers loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Load Model and Transformers\n",
    "# ==============================================================================\n",
    "print(\"Loading model and transformers...\")\n",
    "try:\n",
    "    model = joblib.load(MODEL_PATH)\n",
    "    preprocessor_X = joblib.load(PREPROCESSOR_PATH)\n",
    "    label_encoder_y = joblib.load(LABEL_ENCODER_PATH)\n",
    "    print(f\"✅ Model '{BEST_MODEL_FILENAME}' and transformers loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: Model file not found at {MODEL_PATH}.\")\n",
    "    print(\"Please run the 'model_training.ipynb' notebook first to generate the model file.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading files: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading 2024 data as a proxy for 2027...\n",
      "Loaded 94 rows from year 2024 to serve as prediction base.\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Load 2024 Data to be Used for 2027 Prediction\n",
    "# ==============================================================================\n",
    "print(\"\\nLoading 2024 data as a proxy for 2027...\")\n",
    "try:\n",
    "    con = sqlite3.connect(DB_PATH)\n",
    "    # On utilise la même requête que pour le prétraitement pour garantir la cohérence\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "        DEPARTMENT_CODE,\n",
    "        ROUND(AVG(POVERTY_RATE), 2) as avg_poverty_rate,\n",
    "        ROUND(AVG(UNEMPLOYMENT_RATE), 2) as avg_unemployment_rate,\n",
    "        ROUND(AVG(IMMIGRATION_RATE), 2) as avg_immigration_rate,\n",
    "        ROUND(AVG(NUMBER_OF_VICTIMS), 0) as avg_number_of_victims\n",
    "    FROM ELECTIONS_ALL\n",
    "    WHERE YEAR = 2024\n",
    "    GROUP BY DEPARTMENT_CODE\n",
    "    \"\"\"\n",
    "    prediction_input_df = pd.read_sql_query(query, con)\n",
    "    con.close()\n",
    "    print(f\"Loaded {len(prediction_input_df)} rows from year 2024 to serve as prediction base.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garder une copie des codes département pour plus tard\n",
    "department_codes = prediction_input_df['DEPARTMENT_CODE'].copy()\n",
    "features_to_predict = prediction_input_df.drop(columns=['DEPARTMENT_CODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing data and making predictions for 2027...\n",
      "✅ Predictions generated.\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Preprocess Data and Make Predictions\n",
    "# Le préprocesseur s'attend à recevoir les données avec la même structure que les données d'entraînement.\n",
    "# Cela inclut la colonne 'DEPARTMENT_CODE' qu'il doit encoder.\n",
    "# Nous ne devons donc PAS la supprimer ici.\n",
    "features_to_predict = prediction_input_df\n",
    "# ==============================================================================\n",
    "# Nous gardons une copie des codes département à part, pour l'utiliser dans notre table de résultats finale.\n",
    "department_codes = prediction_input_df['DEPARTMENT_CODE'].copy()\n",
    "\n",
    "print(\"\\nPreprocessing data and making predictions for 2027...\")\n",
    "# Appliquer la transformation apprise (sans la ré-apprendre)\n",
    "X_processed = preprocessor_X.transform(features_to_predict)\n",
    "\n",
    "# Prédire les résultats encodés (ex: 0, 1, 2...)\n",
    "predictions_encoded = model.predict(X_processed)\n",
    "\n",
    "# Décoder les prédictions pour retrouver les noms des partis\n",
    "predictions_decoded = label_encoder_y.inverse_transform(predictions_encoded)\n",
    "print(\"✅ Predictions generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Predicted Winners for 2027 ---\n",
      "   YEAR DEPARTMENT_CODE    WINNER\n",
      "0  2027              01    GAUCHE\n",
      "1  2027              02  E.DROITE\n",
      "2  2027              03    GAUCHE\n",
      "3  2027              04    GAUCHE\n",
      "4  2027              05    CENTRE\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Create the 2027 Predictions DataFrame\n",
    "# ==============================================================================\n",
    "predictions_2027_df = pd.DataFrame({\n",
    "    'YEAR': 2027,\n",
    "    'DEPARTMENT_CODE': department_codes,\n",
    "    'WINNER': predictions_decoded\n",
    "})\n",
    "print(\"\\n--- Predicted Winners for 2027 ---\")\n",
    "print(predictions_2027_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading historical election results...\n",
      "✅ Loaded 281 historical result rows.\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: Load Historical Data\n",
    "# ==============================================================================\n",
    "print(\"\\nLoading historical election results...\")\n",
    "try:\n",
    "    con = sqlite3.connect(DB_PATH)\n",
    "    # On prend les résultats uniques par année et département\n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "        YEAR,\n",
    "        DEPARTMENT_CODE,\n",
    "        WINNER\n",
    "    FROM ELECTIONS_ALL\n",
    "    WHERE WINNER IS NOT NULL\n",
    "    GROUP BY YEAR, DEPARTMENT_CODE, WINNER\n",
    "    \"\"\"\n",
    "    historical_results_df = pd.read_sql_query(query, con)\n",
    "    con.close()\n",
    "    print(f\"✅ Loaded {len(historical_results_df)} historical result rows.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading historical data: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combining historical data with 2027 predictions...\n",
      "Final table for BI contains 375 rows, from year 2017 to 2027.\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: Combine Historical Data with 2027 Predictions and Save\n",
    "# ==============================================================================\n",
    "print(\"\\nCombining historical data with 2027 predictions...\")\n",
    "# Concaténer les résultats historiques et les nouvelles prédictions\n",
    "final_bi_table = pd.concat([historical_results_df, predictions_2027_df], ignore_index=True)\n",
    "\n",
    "print(f\"Final table for BI contains {len(final_bi_table)} rows, from year {final_bi_table['YEAR'].min()} to {final_bi_table['YEAR'].max()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Successfully created/updated the 'ELECTION_RESULTS_FOR_BI' table.\n",
      "You can now connect this table to Power BI or any other BI tool.\n"
     ]
    }
   ],
   "source": [
    "# --- Sauvegarde dans la base de données ---\n",
    "try:\n",
    "    con = sqlite3.connect(DB_PATH)\n",
    "    # 'if_exists='replace'' va écraser la table si elle existe déjà.\n",
    "    # C'est pratique pour pouvoir relancer le script.\n",
    "    final_bi_table.to_sql('ELECTION_RESULTS_FOR_BI', con, if_exists='replace', index=False)\n",
    "    con.close()\n",
    "    print(\"\\n✅ Successfully created/updated the 'ELECTION_RESULTS_FOR_BI' table.\")\n",
    "    print(\"You can now connect this table to Power BI or any other BI tool.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error saving final table to database: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
