{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import joblib to save and load Python objects\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# ML preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ML models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ML evaluation\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL treatement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to db\n",
    "db_path = \"../database/ELECTIONS.db\" \n",
    "\n",
    "# Connect to db\n",
    "conn = sqlite3.connect(db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's agregate our datas per mandants (2017-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEPARTMENT_CODE</th>\n",
       "      <th>WINNER</th>\n",
       "      <th>avg_POVERTY_RATE</th>\n",
       "      <th>avg_UNEMPLOYMENT_RATE</th>\n",
       "      <th>avg_IMMIGRATION_RATE</th>\n",
       "      <th>avg_NUMBER_OF_VICTIMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>GAUCHE</td>\n",
       "      <td>10.80</td>\n",
       "      <td>5.88</td>\n",
       "      <td>12.03</td>\n",
       "      <td>22002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>DROITE</td>\n",
       "      <td>10.50</td>\n",
       "      <td>6.75</td>\n",
       "      <td>11.57</td>\n",
       "      <td>20552.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02</td>\n",
       "      <td>E.DROITE</td>\n",
       "      <td>18.93</td>\n",
       "      <td>11.15</td>\n",
       "      <td>4.83</td>\n",
       "      <td>21547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02</td>\n",
       "      <td>E.DROITE</td>\n",
       "      <td>18.50</td>\n",
       "      <td>12.97</td>\n",
       "      <td>4.37</td>\n",
       "      <td>20206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03</td>\n",
       "      <td>GAUCHE</td>\n",
       "      <td>16.25</td>\n",
       "      <td>8.38</td>\n",
       "      <td>5.34</td>\n",
       "      <td>11864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>03</td>\n",
       "      <td>CENTRE</td>\n",
       "      <td>15.40</td>\n",
       "      <td>9.68</td>\n",
       "      <td>4.93</td>\n",
       "      <td>11763.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>04</td>\n",
       "      <td>GAUCHE</td>\n",
       "      <td>17.13</td>\n",
       "      <td>9.08</td>\n",
       "      <td>8.30</td>\n",
       "      <td>7229.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>04</td>\n",
       "      <td>CENTRE</td>\n",
       "      <td>16.60</td>\n",
       "      <td>10.70</td>\n",
       "      <td>7.60</td>\n",
       "      <td>7030.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>05</td>\n",
       "      <td>CENTRE</td>\n",
       "      <td>14.70</td>\n",
       "      <td>7.55</td>\n",
       "      <td>5.77</td>\n",
       "      <td>5688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>05</td>\n",
       "      <td>CENTRE</td>\n",
       "      <td>13.90</td>\n",
       "      <td>8.68</td>\n",
       "      <td>5.60</td>\n",
       "      <td>6002.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>06</td>\n",
       "      <td>CENTRE</td>\n",
       "      <td>16.27</td>\n",
       "      <td>8.31</td>\n",
       "      <td>14.92</td>\n",
       "      <td>62574.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>06</td>\n",
       "      <td>CENTRE</td>\n",
       "      <td>15.50</td>\n",
       "      <td>9.82</td>\n",
       "      <td>14.33</td>\n",
       "      <td>65274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>07</td>\n",
       "      <td>GAUCHE</td>\n",
       "      <td>14.92</td>\n",
       "      <td>8.71</td>\n",
       "      <td>5.46</td>\n",
       "      <td>10612.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>07</td>\n",
       "      <td>CENTRE</td>\n",
       "      <td>14.30</td>\n",
       "      <td>10.07</td>\n",
       "      <td>5.17</td>\n",
       "      <td>10175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>08</td>\n",
       "      <td>E.DROITE</td>\n",
       "      <td>19.55</td>\n",
       "      <td>9.74</td>\n",
       "      <td>5.88</td>\n",
       "      <td>10181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>08</td>\n",
       "      <td>DROITE</td>\n",
       "      <td>18.90</td>\n",
       "      <td>11.05</td>\n",
       "      <td>5.70</td>\n",
       "      <td>9468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>09</td>\n",
       "      <td>GAUCHE</td>\n",
       "      <td>19.02</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.37</td>\n",
       "      <td>5709.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>09</td>\n",
       "      <td>E.GAUCHE</td>\n",
       "      <td>18.40</td>\n",
       "      <td>11.47</td>\n",
       "      <td>8.13</td>\n",
       "      <td>5457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>E.DROITE</td>\n",
       "      <td>16.92</td>\n",
       "      <td>10.17</td>\n",
       "      <td>8.22</td>\n",
       "      <td>12760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>DROITE</td>\n",
       "      <td>16.30</td>\n",
       "      <td>11.95</td>\n",
       "      <td>7.70</td>\n",
       "      <td>12617.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEPARTMENT_CODE    WINNER  avg_POVERTY_RATE  avg_UNEMPLOYMENT_RATE  \\\n",
       "0               01    GAUCHE             10.80                   5.88   \n",
       "1               01    DROITE             10.50                   6.75   \n",
       "2               02  E.DROITE             18.93                  11.15   \n",
       "3               02  E.DROITE             18.50                  12.97   \n",
       "4               03    GAUCHE             16.25                   8.38   \n",
       "5               03    CENTRE             15.40                   9.68   \n",
       "6               04    GAUCHE             17.13                   9.08   \n",
       "7               04    CENTRE             16.60                  10.70   \n",
       "8               05    CENTRE             14.70                   7.55   \n",
       "9               05    CENTRE             13.90                   8.68   \n",
       "10              06    CENTRE             16.27                   8.31   \n",
       "11              06    CENTRE             15.50                   9.82   \n",
       "12              07    GAUCHE             14.92                   8.71   \n",
       "13              07    CENTRE             14.30                  10.07   \n",
       "14              08  E.DROITE             19.55                   9.74   \n",
       "15              08    DROITE             18.90                  11.05   \n",
       "16              09    GAUCHE             19.02                  10.00   \n",
       "17              09  E.GAUCHE             18.40                  11.47   \n",
       "18              10  E.DROITE             16.92                  10.17   \n",
       "19              10    DROITE             16.30                  11.95   \n",
       "\n",
       "    avg_IMMIGRATION_RATE  avg_NUMBER_OF_VICTIMS  \n",
       "0                  12.03                22002.0  \n",
       "1                  11.57                20552.0  \n",
       "2                   4.83                21547.0  \n",
       "3                   4.37                20206.0  \n",
       "4                   5.34                11864.0  \n",
       "5                   4.93                11763.0  \n",
       "6                   8.30                 7229.0  \n",
       "7                   7.60                 7030.0  \n",
       "8                   5.77                 5688.0  \n",
       "9                   5.60                 6002.0  \n",
       "10                 14.92                62574.0  \n",
       "11                 14.33                65274.0  \n",
       "12                  5.46                10612.0  \n",
       "13                  5.17                10175.0  \n",
       "14                  5.88                10181.0  \n",
       "15                  5.70                 9468.0  \n",
       "16                  8.37                 5709.0  \n",
       "17                  8.13                 5457.0  \n",
       "18                  8.22                12760.0  \n",
       "19                  7.70                12617.0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    DEPARTMENT_CODE,\n",
    "    MAX(WINNER) as WINNER,\n",
    "    ROUND(AVG(POVERTY_RATE), 2) as avg_POVERTY_RATE,\n",
    "    ROUND(AVG(UNEMPLOYMENT_RATE), 2) as avg_UNEMPLOYMENT_RATE,\n",
    "    ROUND(AVG(IMMIGRATION_RATE), 2) as avg_IMMIGRATION_RATE,\n",
    "    ROUND(AVG(NUMBER_OF_VICTIMS), 0) as avg_NUMBER_OF_VICTIMS\n",
    "FROM ELECTIONS_ALL\n",
    "WHERE YEAR IN (2018, 2019, 2020, 2021, 2022, 2023)\n",
    "GROUP BY DEPARTMENT_CODE\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    DEPARTMENT_CODE,\n",
    "    MAX(WINNER) as WINNER,\n",
    "    ROUND(AVG(POVERTY_RATE), 2) as avg_POVERTY_RATE,\n",
    "    ROUND(AVG(UNEMPLOYMENT_RATE), 2) as avg_UNEMPLOYMENT_RATE,\n",
    "    ROUND(AVG(IMMIGRATION_RATE), 2) as avg_IMMIGRATION_RATE,\n",
    "    ROUND(AVG(NUMBER_OF_VICTIMS), 0) as avg_NUMBER_OF_VICTIMS\n",
    "FROM ELECTIONS_ALL\n",
    "WHERE YEAR IN (2017)\n",
    "GROUP BY DEPARTMENT_CODE\n",
    "ORDER BY DEPARTMENT_CODE;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our training datas (first and 2nd mandats)  \n",
    "We have to define our features (X) & target (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features & Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188 entries, 0 to 187\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   DEPARTMENT_CODE        188 non-null    object \n",
      " 1   WINNER                 187 non-null    object \n",
      " 2   avg_POVERTY_RATE       188 non-null    float64\n",
      " 3   avg_UNEMPLOYMENT_RATE  188 non-null    float64\n",
      " 4   avg_IMMIGRATION_RATE   188 non-null    float64\n",
      " 5   avg_NUMBER_OF_VICTIMS  188 non-null    float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 8.9+ KB\n",
      "\n",
      "Missing values check:\n",
      "DEPARTMENT_CODE          0\n",
      "WINNER                   1\n",
      "avg_POVERTY_RATE         0\n",
      "avg_UNEMPLOYMENT_RATE    0\n",
      "avg_IMMIGRATION_RATE     0\n",
      "avg_NUMBER_OF_VICTIMS    0\n",
      "dtype: int64\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(\"DataFrame Info:\")\n",
    "df.info()\n",
    "print(\"\\nMissing values check:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This causes an error during stratified splitting. We'll drop the row with the missing value.\n",
    "df.dropna(subset=['WINNER'], inplace=True)\n",
    "\n",
    "# Fixing error of E.GAUCHE unique sample in the DEPARTMENT_CODE column (which cause not enough categories error in the Dataset split)\n",
    "df = df[df['WINNER'] != 'E.GAUCHE']\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop('WINNER', axis=1)\n",
    "y = df['WINNER']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Désormais, nous devons identifier les features numériques & catégorielles pour les différencier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified Categorical features: ['DEPARTMENT_CODE']\n",
      "Identified Numerical features: ['avg_POVERTY_RATE', 'avg_UNEMPLOYMENT_RATE', 'avg_IMMIGRATION_RATE', 'avg_NUMBER_OF_VICTIMS']\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical and numerical features\n",
    "\n",
    "categorical_features = ['DEPARTMENT_CODE']\n",
    "numerical_features = [col for col in X.columns if col.startswith('avg_')]\n",
    "\n",
    "print(f\"Identified Categorical features: {categorical_features}\")\n",
    "print(f\"Identified Numerical features: {numerical_features}\")\n",
    "print(\"---\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to encode our categorial feature DEPARTMENT_CODE bc the AI Model understand better numerical features  \n",
    "Same thing for StandardScaling (minimize big values to smaller ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Create preprocessor for X (features)\n",
    "# OneHotEncoder for DEPARTMENT_CODE, StandardScaler for numerical features\n",
    "\n",
    "preprocessor_X = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),\n",
    "        ('num', StandardScaler(), numerical_features)\n",
    "    ],\n",
    "    remainder='passthrough' # This will keep any columns not specified (should be none here)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LabelEncoder function will encode our label (target) y and give us different classes of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target (y) categories found: ['CENTRE' 'DROITE' 'E.DROITE' 'GAUCHE']\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encode the target variable y\n",
    "label_encoder_y = LabelEncoder()\n",
    "y_encoded = label_encoder_y.fit_transform(y)\n",
    "\n",
    "print(f\"Target (y) categories found: {label_encoder_y.classes_}\")\n",
    "print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our features & target are encoded, we can split our datas into Training & Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use y_encoded for splitting and for training the models\n",
    "# stratify=y_encoded is good practice for classification to maintain class proportions\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y_encoded,\n",
    "    test_size=0.2,  # 20% for testing\n",
    "    random_state=42, # For reproducibility\n",
    "    stratify=y_encoded\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fiting training datza is very important to avoid data leakage  \n",
    "=> The test set remain completely unseen by the model, so no information will leak by accident into the training set  \n",
    "\n",
    "With our preprocessor_X function, it will do :  \n",
    "- StandardScaling : calculating the mean and standard deviation  \n",
    "- OneHotEncoding : Indentify all unique categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIT the preprocessor on the training data ONLY\n",
    "# TRANSFORM both training and testing data\n",
    "X_train_processed = preprocessor_X.fit_transform(X_train)\n",
    "X_test_processed = preprocessor_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X_train shape: (148, 5)\n",
      "Processed X_train shape: (148, 94)\n",
      "Original X_test shape: (38, 5)\n",
      "Processed X_test shape: (38, 94)\n",
      "y_train shape: (148,)\n",
      "y_test shape: (38,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original X_train shape: {X_train.shape}\")\n",
    "print(f\"Processed X_train shape: {X_train_processed.shape}\")\n",
    "print(f\"Original X_test shape: {X_test.shape}\")\n",
    "print(f\"Processed X_test shape: {X_test_processed.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will export datas into the DB to use it in the new notebook and starting the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created final training and testing DataFrames.\n",
      "Training DataFrame shape: (148, 95)\n",
      "Testing DataFrame shape: (38, 95)\n",
      "\n",
      "---\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat__DEPARTMENT_CODE_01</th>\n",
       "      <th>cat__DEPARTMENT_CODE_02</th>\n",
       "      <th>cat__DEPARTMENT_CODE_03</th>\n",
       "      <th>cat__DEPARTMENT_CODE_04</th>\n",
       "      <th>cat__DEPARTMENT_CODE_05</th>\n",
       "      <th>cat__DEPARTMENT_CODE_06</th>\n",
       "      <th>cat__DEPARTMENT_CODE_07</th>\n",
       "      <th>cat__DEPARTMENT_CODE_08</th>\n",
       "      <th>cat__DEPARTMENT_CODE_09</th>\n",
       "      <th>cat__DEPARTMENT_CODE_10</th>\n",
       "      <th>...</th>\n",
       "      <th>cat__DEPARTMENT_CODE_91</th>\n",
       "      <th>cat__DEPARTMENT_CODE_92</th>\n",
       "      <th>cat__DEPARTMENT_CODE_93</th>\n",
       "      <th>cat__DEPARTMENT_CODE_94</th>\n",
       "      <th>cat__DEPARTMENT_CODE_95</th>\n",
       "      <th>num__avg_POVERTY_RATE</th>\n",
       "      <th>num__avg_UNEMPLOYMENT_RATE</th>\n",
       "      <th>num__avg_IMMIGRATION_RATE</th>\n",
       "      <th>num__avg_NUMBER_OF_VICTIMS</th>\n",
       "      <th>WINNER_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514784</td>\n",
       "      <td>0.215027</td>\n",
       "      <td>0.348804</td>\n",
       "      <td>-0.705740</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.039385</td>\n",
       "      <td>-1.739533</td>\n",
       "      <td>-0.862328</td>\n",
       "      <td>-0.608944</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.660140</td>\n",
       "      <td>1.566399</td>\n",
       "      <td>0.492498</td>\n",
       "      <td>0.785905</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.421170</td>\n",
       "      <td>-0.944949</td>\n",
       "      <td>0.705985</td>\n",
       "      <td>-0.344669</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.411034</td>\n",
       "      <td>-1.072547</td>\n",
       "      <td>1.463456</td>\n",
       "      <td>0.585618</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat__DEPARTMENT_CODE_01  cat__DEPARTMENT_CODE_02  cat__DEPARTMENT_CODE_03  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                      1.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   cat__DEPARTMENT_CODE_04  cat__DEPARTMENT_CODE_05  cat__DEPARTMENT_CODE_06  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                      0.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   cat__DEPARTMENT_CODE_07  cat__DEPARTMENT_CODE_08  cat__DEPARTMENT_CODE_09  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                      0.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   cat__DEPARTMENT_CODE_10  ...  cat__DEPARTMENT_CODE_91  \\\n",
       "0                      0.0  ...                      0.0   \n",
       "1                      0.0  ...                      0.0   \n",
       "2                      0.0  ...                      0.0   \n",
       "3                      0.0  ...                      0.0   \n",
       "4                      0.0  ...                      0.0   \n",
       "\n",
       "   cat__DEPARTMENT_CODE_92  cat__DEPARTMENT_CODE_93  cat__DEPARTMENT_CODE_94  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                      0.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   cat__DEPARTMENT_CODE_95  num__avg_POVERTY_RATE  num__avg_UNEMPLOYMENT_RATE  \\\n",
       "0                      0.0               0.514784                    0.215027   \n",
       "1                      0.0              -1.039385                   -1.739533   \n",
       "2                      0.0               1.660140                    1.566399   \n",
       "3                      0.0              -1.421170                   -0.944949   \n",
       "4                      0.0              -1.411034                   -1.072547   \n",
       "\n",
       "   num__avg_IMMIGRATION_RATE  num__avg_NUMBER_OF_VICTIMS  WINNER_encoded  \n",
       "0                   0.348804                   -0.705740               2  \n",
       "1                  -0.862328                   -0.608944               3  \n",
       "2                   0.492498                    0.785905               3  \n",
       "3                   0.705985                   -0.344669               1  \n",
       "4                   1.463456                    0.585618               0  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature names from the preprocessor to use as column headers\n",
    "try:\n",
    "    # Modern scikit-learn versions have get_feature_names_out()\n",
    "    feature_names = preprocessor_X.get_feature_names_out()\n",
    "except AttributeError:\n",
    "    # Fallback for older versions\n",
    "    ohe_feature_names = preprocessor_X.named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
    "    feature_names = list(ohe_feature_names) + numerical_features\n",
    "\n",
    "# Create DataFrames from the processed numpy arrays\n",
    "X_train_processed_df = pd.DataFrame(X_train_processed, columns=feature_names)\n",
    "X_test_processed_df = pd.DataFrame(X_test_processed, columns=feature_names)\n",
    "\n",
    "# Create DataFrames for the target variable\n",
    "y_train_df = pd.DataFrame(y_train, columns=['WINNER_encoded'])\n",
    "y_test_df = pd.DataFrame(y_test, columns=['WINNER_encoded'])\n",
    "\n",
    "# Reset indices to ensure clean concatenation\n",
    "X_train_processed_df.reset_index(drop=True, inplace=True)\n",
    "y_train_df.reset_index(drop=True, inplace=True)\n",
    "X_test_processed_df.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Combine features and target into final DataFrames\n",
    "train_df = pd.concat([X_train_processed_df, y_train_df], axis=1)\n",
    "test_df = pd.concat([X_test_processed_df, y_test_df], axis=1)\n",
    "\n",
    "print(\"Created final training and testing DataFrames.\")\n",
    "print(f\"Training DataFrame shape: {train_df.shape}\")\n",
    "print(f\"Testing DataFrame shape: {test_df.shape}\")\n",
    "print(\"\\n---\\n\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our datas are preprocessed, we can save them into SQLite DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to database at: ../database/ELECTIONS.db\n",
      "--> Saved processed training data to table 'PROCESSED_TRAIN_DATA'\n",
      "--> Saved processed testing data to table 'PROCESSED_TEST_DATA'\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Connecting to database at: {db_path}\")\n",
    "# Save the processed dataframes as new tables in the database\n",
    "# Using if_exists='replace' allows re-running this notebook without errors\n",
    "train_df.to_sql('PROCESSED_TRAIN_DATA', conn, if_exists='replace', index=False)\n",
    "test_df.to_sql('PROCESSED_TEST_DATA', conn, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"--> Saved processed training data to table 'PROCESSED_TRAIN_DATA'\")\n",
    "print(f\"--> Saved processed testing data to table 'PROCESSED_TEST_DATA'\")\n",
    "print(\"\\n---\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
