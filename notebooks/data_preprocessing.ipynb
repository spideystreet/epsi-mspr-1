{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e19be7d4",
   "metadata": {},
   "source": [
    "# Prétraitement des Données pour la Modélisation Électorale\n",
    "\n",
    "**Objectif :** Ce notebook constitue la première étape du pipeline de machine learning. Il gère l'ensemble du processus de préparation des données :\n",
    "\n",
    "1.  **Chargement des données brutes** depuis les fichiers CSV.\n",
    "2.  **Création/Mise à jour des tables** dans une base de données PostgreSQL.\n",
    "3.  **Création d'une vue unifiée (`elections_all`)** pour agréger toutes les données.\n",
    "4.  **Prétraitement des données** (remplissage des valeurs manquantes, encodage, normalisation).\n",
    "5.  **Sauvegarde des artefacts** (données traitées et transformateurs) pour les étapes suivantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd50fd",
   "metadata": {},
   "source": [
    "## 1. Imports et Chargement de l'Environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eb4d5e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librairies importées et variables d'environnement chargées.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from IPython.display import display\n",
    "\n",
    "load_dotenv()\n",
    "print(\"Librairies importées et variables d'environnement chargées.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20e5be1",
   "metadata": {},
   "source": [
    "## 2. Connexion à la Base de Données PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5c092228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moteur de connexion à la base de données 'ELECTIONS' créé pour l'utilisateur 'postgres'.\n"
     ]
    }
   ],
   "source": [
    "pg_user = os.getenv(\"PG_USER\")\n",
    "pg_password = os.getenv(\"PG_PASSWORD\")\n",
    "pg_host = os.getenv(\"PG_HOST\")\n",
    "pg_port = os.getenv(\"PG_PORT\")\n",
    "pg_dbname = os.getenv(\"PG_DBNAME\")\n",
    "\n",
    "if not all([pg_user, pg_password, pg_host, pg_port, pg_dbname]):\n",
    "    raise ValueError(\"Fichier .env incomplet. Vérifiez les variables PG_USER, PG_PASSWORD, etc.\")\n",
    "\n",
    "db_url = f\"postgresql+psycopg2://{pg_user}:{pg_password}@{pg_host}:{pg_port}/{pg_dbname}\"\n",
    "engine = create_engine(db_url)\n",
    "print(f\"Moteur de connexion à la base de données '{pg_dbname}' créé pour l'utilisateur '{pg_user}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766786cc",
   "metadata": {},
   "source": [
    "## 3. Pré-nettoyage : Suppression de l'Ancienne Vue\n",
    "\n",
    "Pour pouvoir remplacer les tables de base, nous devons d'abord supprimer la vue `elections_all` qui en dépend. Elle sera recréée plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dc5e3a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suppression de la vue 'elections_all' pour permettre la mise à jour des tables...\n",
      "✅ Vue 'elections_all' supprimée (si elle existait).\n"
     ]
    }
   ],
   "source": [
    "print(\"Suppression de la vue 'elections_all' pour permettre la mise à jour des tables...\")\n",
    "drop_view_query = \"DROP VIEW IF EXISTS elections_all;\"\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(drop_view_query))\n",
    "        connection.commit()\n",
    "    print(\"✅ Vue 'elections_all' supprimée (si elle existait).\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors de la suppression de la vue : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26656841",
   "metadata": {},
   "source": [
    "## 4. Chargement des Données depuis CSV et Création des Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "07d1e5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début du chargement des données CSV vers PostgreSQL...\n",
      "✅ Table 'unemployment_data' chargée avec succès.\n",
      "✅ Table 'crime_data' chargée avec succès.\n",
      "✅ Table 'election_data' chargée avec succès.\n",
      "✅ Table 'immigration_data' chargée avec succès.\n",
      "✅ Table 'poverty_data' chargée avec succès.\n",
      "\n",
      "Chargement des tables de base terminé.\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = '../data'\n",
    "\n",
    "TABLE_CONFIG = {\n",
    "    \"unemployment_data\": {\n",
    "        \"csv_file\": \"2017_2024_CHOMAGE_prepared.csv\",\n",
    "        \"columns_map\": {\"ANNEE\": \"YEAR\", \"DEPARTEMENT_CODE\": \"DEPARTMENT_CODE\", \"DEPARTEMENT\": \"DEPARTMENT\", \"TX_CHOMAGE\": \"UNEMPLOYMENT_RATE\"},\n",
    "    },\n",
    "    \"crime_data\": {\n",
    "        \"csv_file\": \"2017_2024_CRIMINALITE_prepared.csv\",\n",
    "        \"columns_map\": {\"ANNEE\": \"YEAR\", \"DEPARTEMENT_CODE\": \"DEPARTMENT_CODE\", \"DEPARTEMENT\": \"DEPARTMENT\", \"NB_DE_VICTIMES\": \"NUMBER_OF_VICTIMS\"},\n",
    "    },\n",
    "    \"election_data\": {\n",
    "        \"csv_file\": \"2017_2024_ELECTIONS_prepared.csv\", \n",
    "        \"columns_map\": {\"ANNEE\": \"YEAR\", \"DEPARTEMENT_CODE\": \"DEPARTMENT_CODE\", \"DEPARTEMENT\": \"DEPARTMENT\", \"GAGNANT\": \"WINNER\", \"NB_INSCRITS\": \"REGISTERED_VOTERS\", \"NB_VOTANTS\": \"VOTERS\"},\n",
    "    },\n",
    "    \"immigration_data\": {\n",
    "        \"csv_file\": \"2017_2024_IMMIGRATION_prepared.csv\",\n",
    "        \"columns_map\": {\"ANNEE\": \"YEAR\", \"DEPARTEMENT_CODE\": \"DEPARTMENT_CODE\", \"DEPARTEMENT\": \"DEPARTMENT\", \"TX_IMMIGRATION\": \"IMMIGRATION_RATE\"},\n",
    "    },\n",
    "    \"poverty_data\": {\n",
    "        \"csv_file\": \"2017_2024_PAUVRETE_prepared.csv\",\n",
    "        \"columns_map\": {\"ANNEE\": \"YEAR\", \"DEPARTEMENT_CODE\": \"DEPARTMENT_CODE\", \"DEPARTEMENT\": \"DEPARTMENT\", \"TX_PAUVRETE\": \"POVERTY_RATE\"},\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"Début du chargement des données CSV vers PostgreSQL...\")\n",
    "for table_name, config in TABLE_CONFIG.items():\n",
    "    try:\n",
    "        csv_path = os.path.join(DATA_DIR, config[\"csv_file\"])\n",
    "        df = pd.read_csv(csv_path, dtype={\"DEPARTEMENT_CODE\": str})\n",
    "        df.rename(columns=config[\"columns_map\"], inplace=True)\n",
    "        if \"DEPARTMENT_CODE\" in df.columns:\n",
    "            df[\"DEPARTMENT_CODE\"] = df[\"DEPARTMENT_CODE\"].astype(str).str.zfill(2)\n",
    "        final_cols = [col for col in config[\"columns_map\"].values() if col in df.columns]\n",
    "        df_to_insert = df[final_cols]\n",
    "        df_to_insert.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "        print(f\"✅ Table '{table_name}' chargée avec succès.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du chargement de la table '{table_name}': {e}\")\n",
    "print(\"\\nChargement des tables de base terminé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefb76f5",
   "metadata": {},
   "source": [
    "## 5. Création de la Vue Agrégée `elections_all`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "38485878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vue 'elections_all' créée ou mise à jour avec succès.\n"
     ]
    }
   ],
   "source": [
    "create_view_query = \"\"\"\n",
    "CREATE OR REPLACE VIEW elections_all AS\n",
    "SELECT\n",
    "    ed.\"YEAR\",\n",
    "    ed.\"DEPARTMENT_CODE\",\n",
    "    ed.\"WINNER\",\n",
    "    cd.\"NUMBER_OF_VICTIMS\",\n",
    "    id.\"IMMIGRATION_RATE\",\n",
    "    pd.\"POVERTY_RATE\",\n",
    "    ud.\"UNEMPLOYMENT_RATE\"\n",
    "FROM\n",
    "    election_data ed\n",
    "LEFT JOIN\n",
    "    crime_data cd ON ed.\"DEPARTMENT_CODE\" = cd.\"DEPARTMENT_CODE\" AND ed.\"YEAR\" = cd.\"YEAR\"\n",
    "LEFT JOIN\n",
    "    immigration_data id ON ed.\"DEPARTMENT_CODE\" = id.\"DEPARTMENT_CODE\" AND ed.\"YEAR\" = id.\"YEAR\"\n",
    "LEFT JOIN\n",
    "    poverty_data pd ON ed.\"DEPARTMENT_CODE\" = pd.\"DEPARTMENT_CODE\" AND ed.\"YEAR\" = pd.\"YEAR\"\n",
    "LEFT JOIN\n",
    "    unemployment_data ud ON ed.\"DEPARTMENT_CODE\" = ud.\"DEPARTMENT_CODE\" AND ed.\"YEAR\" = ud.\"YEAR\";\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(create_view_query))\n",
    "        connection.commit()\n",
    "    print(\"✅ Vue 'elections_all' créée ou mise à jour avec succès.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors de la création de la vue: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d15acb8",
   "metadata": {},
   "source": [
    "## 6. Chargement et Préparation des Données (avec Imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8268bb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape avant imputation : (752, 7)\n",
      "Shape après imputation et suppression des nuls restants : (752, 7)\n",
      "\n",
      "Données brutes chargées, imputées et prêtes pour le traitement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/w9p124nd6jb9srzf94f0v2q80000gn/T/ipykernel_54991/2251613412.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_full = df_full.groupby('department_code', group_keys=False).apply(lambda x: x.ffill())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>department_code</th>\n",
       "      <th>winner</th>\n",
       "      <th>number_of_victims</th>\n",
       "      <th>immigration_rate</th>\n",
       "      <th>poverty_rate</th>\n",
       "      <th>unemployment_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>01</td>\n",
       "      <td>DROITE</td>\n",
       "      <td>20552</td>\n",
       "      <td>11.566667</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>01</td>\n",
       "      <td>DROITE</td>\n",
       "      <td>21081</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>10.3</td>\n",
       "      <td>6.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>01</td>\n",
       "      <td>DROITE</td>\n",
       "      <td>21938</td>\n",
       "      <td>11.833333</td>\n",
       "      <td>10.7</td>\n",
       "      <td>6.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>01</td>\n",
       "      <td>DROITE</td>\n",
       "      <td>19359</td>\n",
       "      <td>11.966667</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>01</td>\n",
       "      <td>DROITE</td>\n",
       "      <td>21465</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>10.8</td>\n",
       "      <td>5.925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year department_code  winner  number_of_victims  immigration_rate  \\\n",
       "0  2017              01  DROITE              20552         11.566667   \n",
       "1  2018              01  DROITE              21081         11.700000   \n",
       "2  2019              01  DROITE              21938         11.833333   \n",
       "3  2020              01  DROITE              19359         11.966667   \n",
       "4  2021              01  DROITE              21465         12.100000   \n",
       "\n",
       "   poverty_rate  unemployment_rate  \n",
       "0          10.5              6.750  \n",
       "1          10.3              6.300  \n",
       "2          10.7              6.050  \n",
       "3          10.5              6.075  \n",
       "4          10.8              5.925  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Aucune valeur nulle détectée dans le jeu de données final.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    query = 'SELECT * FROM elections_all ORDER BY \"DEPARTMENT_CODE\", \"YEAR\";'\n",
    "    df_full = pd.read_sql(query, engine)\n",
    "    df_full.columns = df_full.columns.str.lower()\n",
    "\n",
    "    print(f\"Shape avant imputation : {df_full.shape}\")\n",
    "    df_full = df_full.sort_values(by=['department_code', 'year'])\n",
    "    \n",
    "    df_full = df_full.groupby('department_code', group_keys=False).apply(lambda x: x.ffill())\n",
    "    \n",
    "    df_full.dropna(subset=['winner'], inplace=True)\n",
    "    print(f\"Shape après imputation et suppression des nuls restants : {df_full.shape}\")\n",
    "\n",
    "    print(\"\\nDonnées brutes chargées, imputées et prêtes pour le traitement.\")\n",
    "    display(df_full.head())\n",
    "    \n",
    "    if df_full.isnull().sum().sum() == 0:\n",
    "        print(\"\\n✅ Aucune valeur nulle détectée dans le jeu de données final.\")\n",
    "    else:\n",
    "        print(\"\\n❌ Attention : Des valeurs nulles sont toujours présentes.\")\n",
    "        display(df_full.isnull().sum())\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la lecture des données depuis la vue : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a96364",
   "metadata": {},
   "source": [
    "## 7. Division Temporelle (Train/Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1b670983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du jeu d'entraînement (<= 2023) : (652, 7)\n",
      "Taille du jeu de test (2024) : (94, 7)\n"
     ]
    }
   ],
   "source": [
    "train_df = df_full[df_full['year'] < 2024].copy()\n",
    "test_df = df_full[df_full['year'] == 2024].copy()\n",
    "train_df = train_df[train_df['winner'] != 'E.GAUCHE']\n",
    "print(f\"Taille du jeu d'entraînement (<= 2023) : {train_df.shape}\")\n",
    "print(f\"Taille du jeu de test (2024) : {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4564381",
   "metadata": {},
   "source": [
    "## 8. Définition des Features et de la Cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4a48ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jeux de données X_train/y_train et X_test/y_test définis.\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df.drop(columns=['winner', 'year'])\n",
    "y_train = train_df['winner']\n",
    "X_test = test_df.drop(columns=['winner', 'year'])\n",
    "y_test = test_df['winner']\n",
    "print(\"Jeux de données X_train/y_train et X_test/y_test définis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f08ca64",
   "metadata": {},
   "source": [
    "## 9. Pipeline de Pré-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c14b7ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline de pré-traitement et encodeur de label définis.\n"
     ]
    }
   ],
   "source": [
    "categorical_features = ['department_code']\n",
    "numerical_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "preprocessor_X = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "label_encoder_y = LabelEncoder()\n",
    "print(\"Pipeline de pré-traitement et encodeur de label définis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a3d55",
   "metadata": {},
   "source": [
    "## 10. Application des Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "14055a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformations appliquées aux données.\n"
     ]
    }
   ],
   "source": [
    "X_train_processed = preprocessor_X.fit_transform(X_train)\n",
    "X_test_processed = preprocessor_X.transform(X_test)\n",
    "y_train_encoded = label_encoder_y.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder_y.transform(y_test)\n",
    "print(\"Transformations appliquées aux données.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c2f26c",
   "metadata": {},
   "source": [
    "## 11. Sauvegarde des Données et des Transformateurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4381aed",
   "metadata": {},
   "source": [
    "### 11.1. Reconstruction et Sauvegarde des Données Traitées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ef5cc292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables sauvegardées dans PostgreSQL : 'processed_train_data' et 'processed_test_data'.\n",
      "Colonnes sauvegardées : ['number_of_victims', 'immigration_rate', 'poverty_rate', 'unemployment_rate', 'department_code_01', 'department_code_02', 'department_code_03', 'department_code_04', 'department_code_05', 'department_code_06', 'department_code_07', 'department_code_08', 'department_code_09', 'department_code_10', 'department_code_11', 'department_code_12', 'department_code_13', 'department_code_14', 'department_code_15', 'department_code_16', 'department_code_17', 'department_code_18', 'department_code_19', 'department_code_21', 'department_code_22', 'department_code_23', 'department_code_24', 'department_code_25', 'department_code_26', 'department_code_27', 'department_code_28', 'department_code_29', 'department_code_30', 'department_code_31', 'department_code_32', 'department_code_33', 'department_code_34', 'department_code_35', 'department_code_36', 'department_code_37', 'department_code_38', 'department_code_39', 'department_code_40', 'department_code_41', 'department_code_42', 'department_code_43', 'department_code_44', 'department_code_45', 'department_code_46', 'department_code_47', 'department_code_48', 'department_code_49', 'department_code_50', 'department_code_51', 'department_code_52', 'department_code_53', 'department_code_54', 'department_code_55', 'department_code_56', 'department_code_57', 'department_code_58', 'department_code_59', 'department_code_60', 'department_code_61', 'department_code_62', 'department_code_63', 'department_code_64', 'department_code_65', 'department_code_66', 'department_code_67', 'department_code_68', 'department_code_69', 'department_code_70', 'department_code_71', 'department_code_72', 'department_code_73', 'department_code_74', 'department_code_75', 'department_code_76', 'department_code_77', 'department_code_78', 'department_code_79', 'department_code_80', 'department_code_81', 'department_code_82', 'department_code_83', 'department_code_84', 'department_code_85', 'department_code_86', 'department_code_87', 'department_code_88', 'department_code_89', 'department_code_90', 'department_code_91', 'department_code_92', 'department_code_93', 'department_code_94', 'department_code_95', 'winner_encoded']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ohe_feature_names = preprocessor_X.named_transformers_['cat'].get_feature_names_out(input_features=categorical_features)\n",
    "    feature_names = numerical_features + list(ohe_feature_names)\n",
    "    \n",
    "    # Assurer que les noms des colonnes de features sont en minuscules\n",
    "    feature_names = [f.lower() for f in feature_names]\n",
    "    \n",
    "    X_train_processed_df = pd.DataFrame(X_train_processed.toarray(), columns=feature_names)\n",
    "    X_test_processed_df = pd.DataFrame(X_test_processed.toarray(), columns=feature_names)\n",
    "\n",
    "    train_to_db = X_train_processed_df.copy()\n",
    "    # Assurer que la colonne cible est en minuscules\n",
    "    train_to_db['winner_encoded'] = y_train_encoded\n",
    "    \n",
    "    test_to_db = X_test_processed_df.copy()\n",
    "    test_to_db['winner_encoded'] = y_test_encoded\n",
    "\n",
    "    train_to_db.to_sql('processed_train_data', engine, if_exists='replace', index=False)\n",
    "    test_to_db.to_sql('processed_test_data', engine, if_exists='replace', index=False)\n",
    "    \n",
    "    print(f\"Tables sauvegardées dans PostgreSQL : 'processed_train_data' et 'processed_test_data'.\")\n",
    "    print(f\"Colonnes sauvegardées : {list(train_to_db.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la sauvegarde des données traitées : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9660e4e",
   "metadata": {},
   "source": [
    "### 11.2. Sauvegarde des Transformateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8b8d34e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Préprocesseur sauvegardé : ../database/preprocessor_X.joblib\n",
      "Encodeur de label sauvegardé : ../database/label_encoder_y.joblib\n"
     ]
    }
   ],
   "source": [
    "ARTIFACTS_DIR = '../database'\n",
    "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
    "preprocessor_path = os.path.join(ARTIFACTS_DIR, 'preprocessor_X.joblib')\n",
    "label_encoder_path = os.path.join(ARTIFACTS_DIR, 'label_encoder_y.joblib')\n",
    "joblib.dump(preprocessor_X, preprocessor_path)\n",
    "joblib.dump(label_encoder_y, label_encoder_path)\n",
    "print(f\"Préprocesseur sauvegardé : {preprocessor_path}\")\n",
    "print(f\"Encodeur de label sauvegardé : {label_encoder_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c36e52",
   "metadata": {},
   "source": [
    "## 12. Fermeture de la Connexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "61b7de10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion à la base de données fermée.\n"
     ]
    }
   ],
   "source": [
    "engine.dispose()\n",
    "print(\"Connexion à la base de données fermée.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
