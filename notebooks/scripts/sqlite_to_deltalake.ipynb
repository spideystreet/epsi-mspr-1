{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion de la base de données SQLite vers Delta Lake\n",
    "\n",
    "**Objectif :** Ce notebook convertit les tables de la base de données SQLite `ELECTIONS.db` au format Delta Lake. Les tables Delta résultantes sont stockées localement, en préparation d'une utilisation sur des plateformes comme Databricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dépendances\n",
    "\n",
    "La librairie `deltalake` est requise pour interagir avec le format Delta sans dépendre de Spark.\n",
    "\n",
    "```bash\n",
    "pip install deltalake\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "Définition des chemins d'accès pour la base de données SQLite source et le répertoire de sortie pour les tables Delta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: ../../database/ELECTIONS.db\n",
      "Destination: ../../database/databricks/\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from deltalake import write_deltalake\n",
    "import os\n",
    "\n",
    "# Chemin vers la base de données SQLite source.\n",
    "SQLITE_DB_PATH = '../../database/ELECTIONS.db'\n",
    "\n",
    "# Répertoire de destination pour les tables Delta.\n",
    "DELTA_OUTPUT_DIR = '../../database/databricks/'\n",
    "\n",
    "# Création du répertoire de sortie s'il n'existe pas.\n",
    "os.makedirs(DELTA_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Source: {SQLITE_DB_PATH}\")\n",
    "print(f\"Destination: {DELTA_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script de conversion\n",
    "\n",
    "Le script suivant exécute le processus de conversion :\n",
    "1. Il se connecte à la base de données SQLite pour lister toutes les tables.\n",
    "2. Pour chaque table, il charge les données dans un DataFrame Pandas.\n",
    "3. Le DataFrame est ensuite écrit au format Delta Lake dans le répertoire de destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Démarrage de la conversion ---\n",
      "Tables à convertir : ['UNEMPLOYMENT_DATA', 'CRIME_DATA', 'ELECTION_DATA', 'IMMIGRATION_DATA', 'POVERTY_DATA', 'PROCESSED_TRAIN_DATA', 'PROCESSED_TEST_DATA', 'ELECTION_RESULTS_FOR_BI']\n",
      "\n",
      "Traitement de la table 'UNEMPLOYMENT_DATA'...\n",
      "✅ Table 'UNEMPLOYMENT_DATA' convertie avec succès vers '../../database/databricks/UNEMPLOYMENT_DATA'\n",
      "\n",
      "Traitement de la table 'CRIME_DATA'...\n",
      "✅ Table 'CRIME_DATA' convertie avec succès vers '../../database/databricks/CRIME_DATA'\n",
      "\n",
      "Traitement de la table 'ELECTION_DATA'...\n",
      "✅ Table 'ELECTION_DATA' convertie avec succès vers '../../database/databricks/ELECTION_DATA'\n",
      "\n",
      "Traitement de la table 'IMMIGRATION_DATA'...\n",
      "✅ Table 'IMMIGRATION_DATA' convertie avec succès vers '../../database/databricks/IMMIGRATION_DATA'\n",
      "\n",
      "Traitement de la table 'POVERTY_DATA'...\n",
      "✅ Table 'POVERTY_DATA' convertie avec succès vers '../../database/databricks/POVERTY_DATA'\n",
      "\n",
      "Traitement de la table 'PROCESSED_TRAIN_DATA'...\n",
      "✅ Table 'PROCESSED_TRAIN_DATA' convertie avec succès vers '../../database/databricks/PROCESSED_TRAIN_DATA'\n",
      "\n",
      "Traitement de la table 'PROCESSED_TEST_DATA'...\n",
      "✅ Table 'PROCESSED_TEST_DATA' convertie avec succès vers '../../database/databricks/PROCESSED_TEST_DATA'\n",
      "\n",
      "Traitement de la table 'ELECTION_RESULTS_FOR_BI'...\n",
      "✅ Table 'ELECTION_RESULTS_FOR_BI' convertie avec succès vers '../../database/databricks/ELECTION_RESULTS_FOR_BI'\n",
      "\n",
      "--- Conversion terminée ! ---\n"
     ]
    }
   ],
   "source": [
    "def convert_sqlite_to_delta(db_path, output_dir):\n",
    "    \"\"\"\n",
    "    Convertit toutes les tables d'une base de données SQLite en tables Delta Lake.\n",
    "\n",
    "    Args:\n",
    "        db_path (str): Chemin vers le fichier de base de données SQLite.\n",
    "        output_dir (str): Répertoire où stocker les tables Delta.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Démarrage de la conversion ---\")\n",
    "    \n",
    "    try:\n",
    "        # Connexion à la base de données SQLite pour récupérer les noms de tables.\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = [row[0] for row in cursor.fetchall()]\n",
    "        print(f\"Tables à convertir : {tables}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur: Impossible de lire la liste des tables depuis la base de données : {e}\")\n",
    "        return\n",
    "\n",
    "    # Itération sur chaque table pour la conversion.\n",
    "    for table_name in tables:\n",
    "        try:\n",
    "            print(f\"\\nTraitement de la table '{table_name}'...\")\n",
    "            \n",
    "            # Lecture de la table dans un DataFrame Pandas.\n",
    "            df = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn)\n",
    "            \n",
    "            # Définition du chemin de sortie pour la table Delta.\n",
    "            table_path = os.path.join(output_dir, table_name)\n",
    "            \n",
    "            # Écriture du DataFrame au format Delta Lake.\n",
    "            # Le mode 'overwrite' écrase la table si elle existe déjà,\n",
    "            # permettant une ré-exécution idempotente du script.\n",
    "            write_deltalake(table_path, df, mode='overwrite')\n",
    "            \n",
    "            print(f\"✅ Table '{table_name}' convertie avec succès vers '{table_path}'\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erreur lors du traitement de la table '{table_name}': {e}\")\n",
    "            continue\n",
    "            \n",
    "    conn.close()\n",
    "    print(\"\\n--- Conversion terminée ! ---\")\n",
    "\n",
    "# Exécution de la fonction de conversion.\n",
    "convert_sqlite_to_delta(SQLITE_DB_PATH, DELTA_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérification\n",
    "\n",
    "Après l'exécution du script, le répertoire de sortie (`../../database/databricks/`) contiendra un sous-dossier pour chaque table convertie. Chaque sous-dossier représente une table Delta et inclut des fichiers de données Parquet ainsi qu'un répertoire `_delta_log` contenant le journal des transactions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
