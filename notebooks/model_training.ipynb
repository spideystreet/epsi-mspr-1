{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ANNEE DEPARTEMENT_CODE              DEPARTEMENT    WINNER  NB_INSCRITS  \\\n",
      "0   2024               01                      Ain  E.DROITE       446979   \n",
      "1   2024               02                    Aisne    DROITE        73181   \n",
      "2   2024               03                   Allier  E.DROITE       248529   \n",
      "3   2024               04  Alpes-de-Haute-Provence    GAUCHE       128146   \n",
      "4   2024               05             Hautes-Alpes    GAUCHE       114587   \n",
      "\n",
      "   NB_VOTANTS PARTI_1  VOIX_1   PARTI_2  VOIX_2  ... PARTI_5   VOIX_5 PARTI_6  \\\n",
      "0      311188  GAUCHE   19964    CENTRE  103368  ...  DROITE  27040.0     NaN   \n",
      "1       46620  DROITE   22933  E.DROITE   22409  ...     NaN      NaN     NaN   \n",
      "2      171908  GAUCHE   43029    DROITE   46601  ...     NaN      NaN     NaN   \n",
      "3       90407  GAUCHE   39040  E.DROITE   21536  ...     NaN      NaN     NaN   \n",
      "4       82882  GAUCHE   40743  E.DROITE   34857  ...     NaN      NaN     NaN   \n",
      "\n",
      "   VOIX_6 PARTI_7  VOIX_7 PARTI_8  VOIX_8 PARTI_9  VOIX_9  \n",
      "0     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "1     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "2     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "3     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "4     NaN     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv('../data/elections_prepared.csv')\n",
    "\n",
    "# Check the first rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (248, 23)\n",
      "Test set shape: (62, 23)\n",
      "Target distribution: \n",
      "WINNER\n",
      "CENTRE      136\n",
      "E.DROITE     75\n",
      "GAUCHE       59\n",
      "DROITE       39\n",
      "E.GAUCHE      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define features and target\n",
    "X = df.drop('WINNER', axis=1)\n",
    "y = df['WINNER']\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "    ])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Target distribution: \\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Define models to compare\u001b[39;00m\n\u001b[32m      2\u001b[39m models = {\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mLogistic Regression\u001b[39m\u001b[33m'\u001b[39m: LogisticRegression(max_iter=\u001b[32m1000\u001b[39m),\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mRandom Forest\u001b[39m\u001b[33m'\u001b[39m: RandomForestClassifier(n_estimators=\u001b[32m100\u001b[39m, random_state=\u001b[32m42\u001b[39m),\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mGradient Boosting\u001b[39m\u001b[33m'\u001b[39m: GradientBoostingClassifier(random_state=\u001b[32m42\u001b[39m),\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mXGBoost\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mXGBClassifier\u001b[49m(use_label_encoder=\u001b[38;5;28;01mFalse\u001b[39;00m, eval_metric=\u001b[33m'\u001b[39m\u001b[33mmlogloss\u001b[39m\u001b[33m'\u001b[39m, random_state=\u001b[32m42\u001b[39m),\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mSVC\u001b[39m\u001b[33m'\u001b[39m: SVC(probability=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m      8\u001b[39m }\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Compare models using cross-validation\u001b[39;00m\n\u001b[32m     11\u001b[39m results = {}\n",
      "\u001b[31mNameError\u001b[39m: name 'XGBClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Define models to compare\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "    'SVC': SVC(probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "# Compare models using cross-validation\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Fit on training data\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions on test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'pipeline': pipeline\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} - CV Accuracy: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f}), Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Find best model\n",
    "best_model_name = max(results.items(), key=lambda x: x[1]['cv_mean'])[0]\n",
    "print(f\"\\nBest model: {best_model_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
